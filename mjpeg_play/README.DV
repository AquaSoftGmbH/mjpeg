Building and installation
    1. download and install quicktime4linux-1.3-patched.tar.gz from
       mjpeg.sourceforge.net
    2. download and install libdv-0.8 from libdv.sourceforge.net
    3. get a clean CVS checkout of the development branch of mjpeg_play
    4. configure && make && make install in mjpeg_play
       it should automatically detect libdv if it is installed
    5. download and install dvgrab from 
       http://www.schirmacher.de/arne/dvgrab/index_e.html

Grabbing DV input
    0. I assume you already have a DV camcorder and an IEEE 1394 board and
       everything set up for 1394 capture, otherwise have a look at
       http://linux1394.sourceforge.net/

       Two programs that I found very useful for resolving problems and
       controlling the camcorder through IEEE 1394 are:
       dvcont from http://www.spectsoft.com/idi/dvcont/    and
       gscanbus from http://www.ivistar.de/0500opensource.php3?lang=en

       If your camcorder allows you to record either 12bit or 16bit soundyou
       should make sure to set it to 16bit recording since that is thesound
       format expected by the lavtools. At least my camcorder has 12bitsound
       as the default factory setting, so check that before you start
       recording your videos.
    1. start replay on the camcorder
    2. use dvgrab with the option --format dv2 to capture the DV data inAVI
       type 2 format. Only this format is supported by lav2yuv, capturingwith
       --format dv1 (which is the default in dvgrab) won't work.
    3. If you want to preview and edit (simple cut and paste editing) theraw
       DV files you can use kino from http://www.schirmacher.de/arne/kino/
.
       Make sure to set dv2 format for saving in the preferences.

Using lav2yuv with DV
    * lav2yuv accepts DV avi files directly or as parts of editlists
    * DV input can be recorded in either PAL or NTSC format which is
      automatically detected and handled.
    * for DV input it is not possible to use scaling in lav2yuv, only -s 0 
      is accepted. You should use yuvscaler for scaling to e.g. VCD or SVCD
      size.
    * since you are using a digital signal from a digital source you don't
      have to worry about noise in the signal. I never needed the -n or -d
      options of lav2yuv for my DV input.
    * If you see interlace combs in your output you should usedeinterlacing.
      lav2yuv has the -I flag for this which takes 0...3 as argument:
        -I 0  ...  no deinterlacing (default)
        -I 1  ...  Two-Frame deinterlacing (best), algorithm from the
                   deinterlace project on sourceforge (short description
                   below), the exact behavior can be tuned using theoptions
                   -i # -j # to determine the spatial and temporaltolerance
        -I 2  ...  get the Y component of the odd lines by averaging the
                   adjacent even lines, this is probably good if you wantto
                   scale down in y-direction anyway
        -I 3  ...  get the Y component of the odd lines by copying the even
                   line above it, gives only half the vertical resolution,
                   might be o.k. for VCD output
      Using deinterlacing did not increase the computational time
      significantly in my case since DV decoding, scaling and MPEG encoding
      are far more expensive. If you deinterlace you should use the
      progressive input flag (-F 0) for mpeg2enc, which, as a side effect,
      makes the whole encoding process faster than with -F 3
    * you can extract the sound from the DV files using either lav2wav or
      lavtrans -f w  and encode it to MPEG audio. I didn't have todownsample
      from 48kHz (which is what DV uses) to 44.1kHz before encoding. Myplayer
      accepts SVCDs with 48kHz sound, but I am not sure whether that isalways
      the case. Alternatively you can downsample using sox before encodingthe
      sound in MPEG.

Additional Notes
    1. The recent version of lav2yuv can also read raw YUV data from
       quicktime files that were written in planar YUV 4:2:0 format. Thisis
       one of the output file formats offered by bcast2000 for rendering
       scenes.
    2. This is a short description of the de-interlacing algorithm takenfrom 
       the source file DI_TwoFrame.c from deinterlace.sourceforge.net .This
       algorithm is a combination of simpler algorithms found in Windows
       programs like flaskMPEG or AVIsynth.

///////////////////////////////////////////////////////////////////////////////
// Deinterlace the latest field, attempting to weave wherever it won'tcause
// visible artifacts.
//
// The data from the most recently captured field is always copied to theoverlay
// verbatim.  For the data from the previous field, the following algorithm is
// applied to each pixel.
//
// We use the following notation for the top, middle, and bottom pixels
// of concern:
//
// Field 1 | Field 2 | Field 3 | Field 4 |
//         |   T0    |         |   T1    | scanline we copied in lastiteration
//   M0    |         |    M1   |         | intermediate scanline fromalternate field
//         |   B0    |         |   B1    | scanline we just copied
//
// We will weave M1 into the image if any of the following is true:
//   - M1 is similar to either B1 or T1.  This indicates that no weave
//     artifacts would be visible.  The SpatialTolerance setting controls
//     how far apart the luminances can be before pixels are considered
//     non-similar.
//   - T1 and B1 and M1 are old.  In that case any weave artifact that
//     appears isn't due to fast motion, since it was there in the previous
//     frame too.  By "old" I mean similar to their counterparts in the
//     previous frame; TemporalTolerance controls the maximum squared
//     luminance difference above which a pixel is considered "new".
//
///////////////////////////////////////////////////////////////////////////////
