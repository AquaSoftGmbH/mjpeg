.\"
.TH "MJPEG tools" "MJPEG Linux Square" "MJPEG tools manual"
.LP

MJPEG HOWTO - An introduction to the MJPEG-toolsPraschinger Bernhardv1.31MJPEG capture/editting/replay and MPEG encoding toolset description

.Pp
Introduction


.Pp
I wrote this things down, because I had many sheets with notes on them.
This should be some kind of summary of collected knowledge of this sheets.
Andrew Stevens helped with encoding and VCD knowledge and hints.

.Pp
The mjpegtools are a set of programs that can do recording, playback, editing
and eventual MPEG compression of audio and video under Linux.

.Pp
Although primarily intended for use with capture / playback boards based on the
Zoran ZR36067 MJPEG codec chip, the mjpegtools can easily be used to process
and compress MJPEG video streams captured using xawtv using simple
frame-buffer devices.

.Pp
The HOWTO for the tools intended to give an an introduction to the MJPEG-tools
and the creation of MPEG 1/2 videos. VCD and SVCD, and the transcoding of 
existing mpeg streams.

.Pp
For more information about the programs read the corresponding man-page.

.Pp
Achtung es gibt auch eine deutsche Version bei:

.Pp
There is also a manpage of this text, you can read it with
\(rqman mjpegtools\(rq if installed. 

.Pp
The text version of this text is aviabel via cvs, you should get it with a
tarball or the precompiled package (RPM and deb).

.Pp
Unsorted list of usefull Hints


.Pp
You have to compile and install the mjpeg_play package, for this read the
README & REQUIRED_SOFTWARE & INSTALL.
If you do not want to compile it, you can download the mjpeg .RPM or .DEB
package at sourceforge.

.Pp
There is a script in the scripts/ directory. This script is something that
show's you a way how it can be done. It also creates (under certain
circumstances) videos that look quite good. Better videos you only get by
tuning the parameters yourself. 

.Pp
You will usually have to load the drivers for the Buz or DC10 or LML33 cards.So you have to run the update script providing as option the name of your card
you have. The script is usually in /usr/src/driver-zoran/.
The zoran kernel driver below the kernel 2.4.4 do not work.
You have to use the driver aviable from:

.Pp
The driver for the Matrox Marvel card also works, more information about it:

.Pp
If you compile the tools on a P6 based computer (PPro, P-II, P-III, P-4,
Athlon,Duron) then never try to let them run on a P5 based computer
(Pentium, Pentium-MMX, K6, K6-x, Cyrix, Via, Winchip). You'll get a 
\(rqillegal instruction\(rq and the program won't work.

.Pp
If lav2yuv dumps core then probably the problem is that in building the
quicktime4linux no dv support was used. To enable it take a look on the docs
of the quicktime4linux lib. You will have to use something for configuring the  
lib like that \f(CR\&./configure --use-dv --use-firewire\fP\&.
After that lav2XXX functions should not dump core anymore. This is the case if
your are using digital camera and converting the dv avi format into SVCD
or some other format using mjpegtools.

.Pp
Start xawtv to see if you get an picture. If you want to use HW-playback of
the recorded streams you have to start xawtv (any TV application works) once
to get the streams played back. You should also check the settings of your
mixer in the sound card.

.Pp
If you compile the tools on a other platform, not all tools might work.
The v4l (video4linux) stuff will very likely fail to work.

.Pp
Never try to stop or start the TV application when lavrec runs. If you start
or stop the TV application lavrec will stop recording, or your computer could
get \(rqfrozen\(rq\&.

.Pp
One last thing about the data you get before we start:

.Pp
.DS
.sp 
.ft RR
.nf
Audio: ( Samlperate * Channels * Bitsize ) / (8 * 1024)
CD Quality:(44100 Samples/sec * 2 Chanels * 16 Bit) / (8 * 1024)=172,2 kB/sec

The 8 * 1024 convert the value from bit/sec to kByte/sec

Video: (width * height * framerate * quality ) / (200 * 1024)
PAL HALF Size : (352 * 288 * 25 * 80) / (200 * 1024) = 990 kB/sec
PAL FULL size : (720 * 576 * 25 * 80) / (200 * 1024) = 4050 kB/sec
NTSC HALF size: (352 * 240 * 30 * 80) / (200 * 1024) = 990 kB/sec
NTSC FULL size: (720 * 480 * 30 * 80) / (200 * 1024) = 4050 kB/sec
.DE
.fi 
.ec
.ft P
.sp

.Pp
The 1024 converts the Bytes to kBytes. Not every card can record the size
mentioned. The Buz and Marvel G400 for example can only record a size of 
720x576 when using -d 1, the DC10 records a size of 384x288 when using -d 2.

.Pp
When you add audio and video datarate, this is what your hard disk has to be 
able to write constantly streaming, else you will have lost frames.

.Pp
If you want to play with the \fB--mjpeg-buffer-size\fP\&. Remember the value 
should be at least so big that one frame fits into it. The size of one frame 
is: (width * height * quality ) / (200 * 1024) = kB 
If the buffer is to small the rate calculation doesn't match any more and 
buffer overflows can happen. The maximal value is 512kB.

.Pp
How video works, and the difference between the video type is explained here:

.Pp
There you also find how to create MPEG Still Images for VCD/SVCD.

.Pp
Recording videos


.Pp

.SH lavrec examples


.Pp
Recording with lavrec look's like this:

.Pp
\f(CR> lavrec -f a -i P -d 2 record.avi\fP

.Pp
.nr ll +1
.nr t\n(ll 2
.if \n(ll>1 .RS
.IP ""
.nr bi 1

.Pp
Should start recording now,
.IP "-f a"
.nr bi 1

.Pp
use AVI as output format,
.IP "-i P"
.nr bi 1

.Pp
use as input source the SVHS-In with PAL format,
.IP "-d 2"
.nr bi 1

.Pp
the size of the pictures are half size (352x288)
.IP "record.avi"
.nr bi 1

.Pp
name of the created file.
.if \n(ll>1 .RE
.nr ll -1

.Pp
Recording is finished by pressing Crtl-C (nowadays: Strg-C). 
Sometimes useing \fB-f A\fP instead of \fB-f a\fP might be necessary

.Pp
Other example:

.Pp
\f(CR> lavrec -f q -i n -d 1 -q 80 -s -l 80 -R l -U record.avi \fP

.Pp
.nr ll +1
.nr t\n(ll 2
.if \n(ll>1 .RS
.IP ""
.nr bi 1

.Pp
Should start recording now, 
.IP "-f q"
.nr bi 1

.Pp
use Quicktime as output format, 
.IP "-i n"
.nr bi 1

.Pp
use Composite-In with NTSC format, 
.IP "-d 1"
.nr bi 1

.Pp
record pictures with full size (640x480) 
.IP "-q 80"
.nr bi 1

.Pp
set the quality to 80% of the captured image 
.IP "-s"
.nr bi 1

.Pp
use stereo mode (default mono) 
.IP "-l 80"
.nr bi 1

.Pp
set the recording level to 80% of the max during recording 
.IP "-R l"
.nr bi 1

.Pp
set the recording source to Line-In 
.IP "-U"
.nr bi 1

.Pp
With this lavrec uses the read instead of mmap for recording this is needed if your sound card does not
support the mmap for recording.
.if \n(ll>1 .RE
.nr ll -1

.Pp
The cards record at a different size in PAL when recording at -d 1 : 
BUZ and LML33: 720x576 and the DC10: 768x576

.Pp
Other example:

.Pp
\f(CR> lavrec -f a -i t -q 80 -d 2 -C europe-west:SE20 test.avi\fP

.Pp
.nr ll +1
.nr t\n(ll 2
.if \n(ll>1 .RS
.IP ""
.nr bi 1

.Pp
Should start recording now, 
.IP "-f a"
.nr bi 1

.Pp
use AVI as output format, 
.IP "-i t"
.nr bi 1

.Pp
use tuner input, 
.IP "-q 80"
.nr bi 1

.Pp
set the quality to 80% of the captured image 
.IP "-d 2"
.nr bi 1

.Pp
the size of the pictures are half size (352x288) 
.IP "-C"
.nr bi 1

.Pp
choose TV channels, and the corresponding -it and -iT (video source:
TV tuner) can currently be used on the Marvel G200/G400 and the Matrox
Millenium G200/G400 with Rainbow Runner extension (BTTV-Support is under
construction). For more information on how to make the TV tuner parts of these
cards work, see the Marvel/Linux project on:
.if \n(ll>1 .RE
.nr ll -1

.Pp
Last example:

.Pp
\f(CR> lavrec -f a -i p -g 352x288 -q 80 -s -l 70 -R l --software-encoding
test03.avi\fP

.Pp
The two new options are \fB-g 352x288\fP, which sets the size of the
video to be recorded when using \fB--software-encoding\fP, this enables
the software encoding of the recorded images. With this option you can also
record from a bttv based card. The processor load is high. This option only
works for generic video4linux cards (such as the brooktree-848/878 based 
cards), it doesn't work for zoran-based cards.

.Pp

.SH Other recording hints


.Pp
All lavtools accept a file description like file*.avi, so you do not have
to name each file, but that would also be a posibillity to do. 

.Pp
Note: More options are described in the man-page, but with this you should be able to start.

.Pp
How about some hints as to sensible settings. Turn the quality to 80%
or more for -d 2 capture. At full resolution as low as 40% seems to
be visually \(rqperfect\(rq\&. -d 2 is already better than VHS video
(a *lot*!). For a Marvel you should not set the quality higher than 50 when
you record at full size (-d 1). If you use higher settings (-q 60) it is
more likely that you encounter problems. If you use much higher settings you
will encounter framedropps. 
If you're aiming to create VCD's then there is little to be gained
recording at full resolution as you need to reduce to -d 2 resolution
later anyway.

.Pp

.SH Some information about the typical lavrec output while recording


.Pp
0.06.14:22 int: 00040 lst:0 ins:0 del:0 ae:0 td1=0.014 td2=0.029

.Pp
It should look like this. The fist part shows the time lavrec is recording.
\fBint:\fP the interval between two frames. \fBlst:\fP the number of
lost frames. \fBins and del:\fP are the number of frames inserted and
deleted for sync correction. \fBae:\fP number of audio errors.
\fBtd1 and td2\fP are the audio/video time-difference.

.Pp
.nr ll +1
.nr t\n(ll 0
.if \n(ll>1 .RS
.nr bi 1
.Pp

\fB(int) frame interval\fP should be around 33 (NTSC) or 40
(PAL/SECAM). If it is very different, you'll likely get a bad recording
and/or many lost frames
.nr bi 1
.Pp

\fB(lst) lost frames\fP are bad and mean that something is not working
very well during recording (too slow HD, too high CPU usage, ...) Try
recording at a with a greater declimation, and a lower quality
.nr bi 1
.Pp

\fB(ins, del) inserted OR deleted frames\fP of them are normal \(->
sync. If you have many lost AND inserted frames, you're asking too much,
your machine can't handle it. Take less demanding options, try to use
an other sound card.
.nr bi 1
.Pp

\fB(ae) audio errors\fP are never good. Should be 0
.nr bi 1
.Pp

\fB(td1, td2) time difference\fPis always floating around 0, unless
sync correction is disabled (--synchronization!=2, 2 is default).
.if \n(ll>1 .RE
.nr ll -1

.Pp
.SH Notes about \(rqinterlace field order - what can go wrong and how to fix it\(rq


.Pp
Firstly, what does it mean for interlace field order to be wrong.

.Pp
The whole mjpegtools image processing chain is frame-orientated. Since it
is video material that is captured each frame comprised a top field (the
0th, 2nd, 4th and so lines) and a bottom field (the 1st, 3rd, 5th and so
on lines).

.Pp

.Pp
There are three bad things that can happen with fields


.Pp
.nr ll +1
.nr el +1
.nr t\n(ll 1
.nr e\n(el 0 1
.af e\n(el \*(f\n(el
.if \n(ll>1 .RS
.nr bi 1
.Pp

This is really only an issue for Movies in PAL video where each Film
frame is sent as a pair of fields. These can be sent top or bottom field
first and sadly its not always the same, though bottom-first appears to be
usual. If you capture with the wrong field order (you start capturing
each frame with a bottom rather than a top or vice versa) the frames of the
movie get split *between* frames in the stream. Played back on a
TV where each field is displayed on its own this is harmless. The sequence
of fields played back is exactly the same as the sequence of fields
broadcast. Unfortunately, playing back on a Computer monitor where both
fields of a frame appear at once it looks *terrible* because each
frame is effectively mixing two moments in time 1/25sec apparent.
.nr bi 1
.Pp

The two fields can simply be swapped somehow so that top gets treat
as bottom and bottom treat as top. Juddering and \(rqslicing\(rq is the
result. This occasionally seems to happen due to hardware glitches in the
capture card.
.nr bi 1
.Pp

Somewhere in capturing/processing the *order* in time of the two
fields in each frame can get mislabeled somehow. This is not good as it
means that when playback eventually takes place a field containing an
image sampled earlier in time comes after an image sampled later.
Weird \(rqjuddering\(rq effects are the results.
.if \n(ll>1 .RE
.nr el -1
.nr ll -1

.Pp

.Pp
How can I recognize if I have one of these Problems ? 


.Pp
.nr ll +1
.nr el +1
.nr t\n(ll 1
.nr e\n(el 0 1
.af e\n(el \*(f\n(el
.if \n(ll>1 .RS
.nr bi 1
.Pp
This can be hard to spot. If you have mysteriously flickery pictures
during playback try encoding a snippet with the reverse field-order
forced (see below). If things improve drastically you know what the
problem was and what the solution is! 
.nr bi 1
.Pp
The two fields can simply be swapped somehow so that top gets treat
as bottom and bottom treat as top. Juddering and \(rqslicing\(rq is
the result. This occasionally seems to happen due to hardware glitches in
the capture card.
.nr bi 1
.Pp
Somewhere in capturing/processing the *order* in time of the two
fields in each frame can get mislabeled somehow. This is not good as it
means that when playback eventually takes place a field containing an image
sampled earlier in time comes after an image sampled later. Weird 
\(rqjuddering\(rq effects are the results.
.if \n(ll>1 .RE
.nr el -1
.nr ll -1

.Pp
If you use glav or lavplay be soure that you also use the \fB-F/--flicker\fP
option. This disables some things that make the picture to look better,
and problems are not that hard to be recognized.

.Pp
If you want to look at the video you can also use yuvplay:

.Pp
\f(CR> lav2yuv \(br ... \(br yuvplay\fP

.Pp
You should see here also some problems.

.Pp

.Pp
How can you fix it? 


.Pp
.nr ll +1
.nr el +1
.nr t\n(ll 1
.nr e\n(el 0 1
.af e\n(el \*(f\n(el
.if \n(ll>1 .RS
.nr bi 1
.Pp
To fix this one the fields need to be \(rqshifted\(rq through
the frames. Use yuvscaler's \fB-M BOTT_FORWARD/TOP_FORWARD\fP to
shift the way fields are allocated to frames. You can find out the current
field order for an MJPEG file by looking at the first few lines of debug
output from: \fB> lav2yuv -v 2 the_mjpeg_file > /dev/null\fP 
Or re-record exchanging \fB-f a\fP for \fB-F A\fP or vice-versa. 
.nr bi 1
.Pp
This isn't too bad either. Use a tool that simply swaps the top
and bottom fields a second time. yuvscaler can do this use the
\fB-M LINE_SWITCH\fP\&. 
.nr bi 1
.Pp
Is easy to fix. Either tell a tool someplace to relabel the fields or
simply tell the player to play back in swapped order (the latter can be done
\(rqindirectly\(rq by telling mpeg2enc when encoding to \fBreverse the
flag (-z b\(brt)\fP that tells the decoder which field order to use. 
.if \n(ll>1 .RE
.nr el -1
.nr ll -1

.Pp

.Pp
\fBIn order to determine exactly what type of interlacing problem you
have, you need to extract some frames from the recorded stream and take a
look at them:\fP

.Pp
.DS
.sp 
.ft RR
.nf
> mkdir pnm 
> lav2yuv -f 40 video.avi \(br y4mtoppm \(br pnmsplit - pnm/image%d.pnm 
> rm pnm/image?.pnm 
> cd pnm 
> xv 
.DE
.fi 
.ec
.ft P
.sp

.Pp
First we create a directory where we store the images. The lav2yuv -f 40
writes only the first 40 frames to stdout. The mjpegtools y4mtoppm converts
the frames to pnm images and the pnmsplit splits the picture into two
frames in the picture to two single pictures. Then we remove the first 10
images because pnmsplit does not support the %0xd numbering. Without
a leading zero in the number, the files will be sorted in the wrong order,
leading to a confusing playback.

.Pp
Use your favourite grafic program (xv for example) to view the pictures. As
each picture only contain one field out of two, they will appear scaled
vertically. If you look at the pictures you should see the movie slow
advancing.

.Pp
If you have a film you should always see 2 pictures that are nearly the same
after each other. Nearly because the film frame is split into two field for
broadcasting. You can notice this rather easy if you have comb efects when
you pause the film because both field should fit together well. The two
pictures that belong together should have an even number and the following
odd number. So if you take a look on pictures: 4 and 5 are nearly identical,
5 and 6 differ (have movement), 6 and 7 identical, 7 and 8 differ , ....

.Pp
To fix this problem you have to use yuvscaler's \fB-M BOTT_FORWARD or
TOP_FORWARD\fP\&. You can also have the problem that the field order
(top/bottom) is still wrong. You may have to use yuvscaler a second time
with \fB-M LINE_SWITCH\fP, or use the mpeg2enc \fB-z (b\(brt)\fP option.

.Pp
To see if you guessed correctly, extract the frames again, reordering them
using yuvscaler:

.Pp
\f(CR> lav2yuv -f 40 video.avi \(br yuvscaler -M OPTION \(br y4mtoppm \(br pnmsplit - pnm/image%d.pnm \fP

.Pp
Where \(rqOPTION\(rq is what you think it will corrects the problem.
This is for material converted from film. Material produced directly for TV
is addressed below.

.Pp

.Pp
Hey, what about NTSC movies ?


.Pp
Movies are broadcast in NTSC using \(rq3:2\(rq pulldown which means
that half the capture frames contain fields from 1 movie frame and half
fields from 2 frames. To undo this effect for efficient MPEG encoding you
need to use yuvkineco. 

.Pp
If you have an interlaced source like a TV camera you have a frame consists
of two fields that are recorded at different points in time and shown after
each other. Spotting the problem here is harder. You need to find something
moving hoziontally from the left to the right. When you extract the fields,
the thing should move in small steps from the left to the right, not one
large step forward, small step back, large forward, small back......
You have to use the same options mentioned aboth to correct the problem.

.Pp
Do not expect that the field order is always the same (top- or bottom-first)
It my change between the channels, between the films and it may even change
in a film. If it changes constant you may have to encode with the mpeg2enc
-I 1 or even -I 2.

.Pp
You can only have this problems if you record at full size !!! 

.Pp
Creating videos from images


.Pp
You can use jpeg2yuv to create a yuv stream from separate JPEG images. This
stream is sent to stdout, so that it can either be saved into a file,
encoded directly to a mpeg video using mpeg2enc or used for anything else.

.Pp
Saving an yuv stream can be done like this:

.Pp
\f(CR> jpeg2yuv -f 25 -j image%05d.jpg > result.yuv\fP

.Pp
Creates the file result.yuv containing the yuv video data with 25 FPS. The
-f option is used to set the frame rate. Note that image%05d.jpg
means that the jpeg files are named image00000.jpg, image00001.jpg and so
on. (05 means five digits, 04 means four digits, etc.)

.Pp
If you want to encode a mpeg video directly from jpeg images without saving
a separate video file type:

.Pp
\f(CR> jpeg2yuv -f 25 -j image%05d.jpg \(br mpeg2enc -o mpegfile.m1v\fP

.Pp
Does the same as above but saves a mpeg video rather than a yuv video. See
mpeg2enc section for details on how to use mpeg2enc.

.Pp
You can also use yuvscaler between jpeg2yuv and mpeg2enc. If you want to
create a SVCD from your source images:

.Pp
\f(CR> jpeg2yuv -f 25 -j image%05d.jpg \(br yuvscaler -O SVCD
\(br  mpeg2enc -f 4 -o video.m2v\fP

.Pp
You can use the -b option to set the number of the image to start with. The
number of images to be processed can be specified with the -n number. For
example, if your first image is image01.jpg rather than image00.jpg, and 
you only want 60 images to be processed type:

.Pp
\f(CR>jpeg2yuv -b 1 -f 25 -n 60 -j image*.jpg \(br yuv2lav -o stream_without_sound.avi\fP

.Pp
Adding the sound to the stream then:

.Pp
\f(CR> lavaddwav stream_without_sound.avi sound.wav stream_with_sound.avi\fP

.Pp
For ppm input there is the ppmtoy4m util, there is also a manpage for ppmtoy4m.

.Pp
So to create a mpeg video try this:

.Pp
\f(CR>cat *.ppm \(br ppmtoy4m -o 75 -n 60 -F 25:1 \(br mpeg2enc -o output.m1v\fP

.Pp
Cat's each *.ppm file to ppmtoy4m. There the first 75 frames (pictures) are
ignored and next 60 are encoded by mpeg2enc to output.m1v. You can run it
without the -o and -n option. The -F  options sets the frame rate, default
is NTSC (30000:1001), for PAL you have to use -F 25:1.

.Pp
Other picture formats can also be used if there is a converter to ppm.

.Pp
\f(CR>ls *.tga \(br xargs -n1 tgatoppm \(br ppmtoy4m \(br yuvplay\fP

.Pp
A list of filenames (ls *.tga) is given to xargs that executes the tgatoppm 
with one (-n 1) argument per call, and feeds the output into ppmtoy4m.
This time the video is only shown on the screen. The xargs is only needed
if the converter (tgatoppm), can only operate on a single image at a time.

.Pp
If you want to use the ImageMagick 'convert' tool (a Swiss Army Knife) try:

.Pp
\f(CR>convert *.gif ppm:- \(br ppmtoy4m \(br yuvplay\fP

.Pp
That means take all '.jpg' images in directory, convert to PPM format,
and pipe to stdout, then ppmtoy4m processes them ....

.Pp
Checking if recording was successful


.Pp
You can use lavplay or glav. \fBIMPORTANT: NEVER\fP try to run xawtv
and lavplay or glav with hardware playback, wont work. If you want 
software playback it works fine.

.Pp
\f(CR>lavplay -p S record.avi\fP

.Pp
You should see the recorded video and hear the sound. But the decoding
of the video is done by the CPU. Your system has quite a heavy load.
You don't need xawtv or anything, though.

.Pp
The better way:

.Pp
\f(CR>lavplay -p H record.avi\fP

.Pp
The video is decoded and played by the hardware. The system load is
now very low. This will play it back on-screen using the hardware.

.Pp
You might also try:

.Pp
\f(CR> lavply -p C record.avi\fP

.Pp
Which will play it back using the hardware, but to the videooutput of
the card.

.Pp
\f(CR> glav record.avi\fP

.Pp
Does the same as lavplay, but you have an nice gui. The options for
glav and lavplay are nearly the same. Using no option SW playback is used.

.Pp
Using hardware playback a signal for the Composite and SVHS OUT is
generated, so you can view the movie on your TV.

.Pp
\f(CR> lav2yuv test.eli \(br yuvplay\fP

.Pp
Is a other way to get the video, without sound. You can use yuvplay
once in the encoding command. When you use yuvplay in the encconding
command you see the changes made by filters, and scaling. You can also
use it for slow-motion debugging.

.Pp
\fBNOTE:\fP After loading the driver's you have to start xawtv to
set up some things lavplay and glav do not, but they are needed for
HW-Playback. Don't forget to close xawtv !!

.Pp

.Pp
\fBNOTE2:\fP Do not try to send glav an lavplay into background, wont work
correct !!!

.Pp
\fBNOTE3:\fP SECAM playback is now (12.3.2001) only in monochrome, but the
recording and encoding is done right.

.Pp
\fBNOTE4:\fP You reduce your quality by using low quality cables. Normally
you can't see this, but when there is text you might notice a small
shadow. When you see this you should change the cable.

.Pp
\fBComming soon:\fP There is a tool, that makes recoding videos very simple
named Linux Studio. You can download it at:

.Pp
Edit the video


.Pp
.SH Edit with glav


.Pp
Most tasks can be easily done by glav. Like deleting parts of the video,
cut paste and copy parts of the videos.

.Pp
glav button description

.Pp

.Pp

.Pp
The modifications should be saved because glav does not edit (not
destructive) the video. This means that the video is left untouched,
and the modifications are kept in an extra \(rqEdit List\(rq file.
Readable with a text editor. This files can be used as an input file for the 
lavtools, like lav2wav, lav2yuv, lavtrans.

.Pp
If you want to cut off the beginning and the end of the stream mark the
beginning and the and, and use the \(rqsave select\(rq button. The
edit list file is than used as input for the lavtools. If you want to split
a recorded video to some smaller parts, simply select the parts and 
then save each part to a different listfile.

.Pp
You can see all changes to the video and sound NOW, you do not need to
recalculate something.

.Pp
If you want to get an \&"destructive\&" version of your edited video use:

.Pp
\f(CR> lavtrans -o short_version.avi -f a editlist.eli\fP

.Pp
.nr ll +1
.nr t\n(ll 2
.if \n(ll>1 .RS
.IP "-o"
.nr bi 1

.Pp
specifies the output name
.IP "-f a"
.nr bi 1

.Pp
specifies the output format (AVI for example)
.IP "editlist.eli"
.nr bi 1

.Pp
is the list file where the modifications are described.
You generate the list file with the \&"save all\&" or \(rqsave select\(rq
buttons in glav.
.if \n(ll>1 .RE
.nr ll -1

.Pp

.SH Unify videos


.Pp
\f(CR> lavtrans -o stream.movtar -f m record_1.avi record_2.avi ... record_n.avi\fP

.Pp
.nr ll +1
.nr t\n(ll 2
.if \n(ll>1 .RS
.IP "-o"
.nr bi 1

.Pp
specifies the outputfile name
.IP "-f m"
.nr bi 1

.Pp
specifies the output format, movtar in this case
.if \n(ll>1 .RE
.nr ll -1

.Pp
This is not that often needed. Keep in your mind that there is the 2GB
file-size-limit on 32Bit systems with an older glibc.

.Pp

.SH Separate sound


.Pp
\f(CR> lavtrans -o sound.wav -f w stream.avi\fP

.Pp
Creates a wav file with the sound of the stream.avi
Maybe need if you want to remove noise or something else, or you want
to convert it to an an other sound format for other use.

.Pp
An other version of splitting the sound is:

.Pp
\f(CR> lav2wav editlist.eli >sound.wav\fP

.Pp

.SH Separate images


.Pp
\f(CR>mkdir jpg; lavtrans -o jpg/image%05d.jpg -f i stream.avi\fP

.Pp
First create the directory \(rqjpg\(rq\&. Then lavtrans will create
single JPG images in the jpg directory from the stream.avi file. The
files will be named: image00000.jpg, image00001.jpg ....

.Pp
The jpg images created contain the whole picture. But if you have recorded 
at full size the images are stored interlaced. Usually the picture viewers
show only the first field in the jpg file.

.Pp


.Pp

.Pp
If you want to have the image in a single file you can use that version

.Pp
\f(CR> lav2yuv -f 1 stream.avi \(br y4mtoppm -L >file.pnm\fP

.Pp
If you want to split the fields into single files use that:

.Pp
\f(CR>  lav2yuv -f 5 ../stream.avi \(br y4mtoppm \(br
pnmsplit - image%d.pnm\fP

.Pp
Maybe interesting if you need sample images and do not want to play
around with grabbing a single image.

.Pp

.SH Creating movie transitions


.Pp
Thanks to pHilipp Zabel's lavpipe, we can now make simple transitions
between movies or combine multiple layers of movies.

.Pp
pHilipp wrote this HOWTO on how to make transitions:

.Pp
Let's assume simple this scenery: We have two input videos, intro.avi
and epilogue.mov and want make intro.avi transist into epilogue.mov with a
duration of one second (that is 25 frames for PAL or 30 frames for NTSC).

.Pp
Intro.avi and epiloque.mov have to be of the same format regarding
frame rate and image resolution, at the moment. In this example they
are both 352x288 PAL files. intro.avi contains 250 frames and
epilogue.mov is 1000 frames long.

.Pp
Therefore our output file will contain: 

.Pp
.nr ll +1
.nr t\n(ll 2
.if \n(ll>1 .RS
.IP ""
.nr bi 1

.Pp
the first 225 frames of intro.avi
.IP ""
.nr bi 1

.Pp
a 25 frame transition containing the last 25 frames of intro.avi and
the first 25 frames of epilogue.mov
.IP ""
.nr bi 1

.Pp
the last 975 frames of epilogue.mov
.if \n(ll>1 .RE
.nr ll -1

.Pp
We could get the last 25 frames of intro.avi by calling:

.Pp
\f(CR>lav2yuv -o 225 -f 25 intro.avi\fP

.Pp
\fB-o 255\fP, the offset, tells lav2yuv to begin with frame # 225 and
\fB -f 25\fP makes it output 25 frames from there on.

.Pp
Another possibility is:

.Pp
\f(CR> lav2yuv -o -25 intro.avi\fP

.Pp
Since negative offsets are counted from the end.

.Pp
And the first 25 frames of epilogue.mov:

.Pp
\f(CR> lav2yuv -f 25 epilogue.mov\fP

.Pp
\fB-o\fP defaults to an offset of zero

.Pp

.Pp
But we need to combine the two streams with lavpipe. So the call would be:

.Pp
\f(CR> lavpipe \(rqlav2yuv -o 255 -f 25 intro.avi\(rq \(rqlav2yuv -f 25 epilogue.mov\(rq \fP

.Pp
The output of this is a raw yuv stream that can be fed into 
transist.flt.

.Pp
transist.flt needs to be informed about the duration of the transition and
the opacity of the second stream at the beginning and at the end of the
transition:

.Pp
.nr ll +1
.nr t\n(ll 2
.if \n(ll>1 .RS
.IP "-o num"
.nr bi 1

.Pp
opacity of second input at the beginning [0-255]
.IP "-O num"
.nr bi 1

.Pp
opacity of second input at the end [0-255]
.IP "-d num"
.nr bi 1

.Pp
duration of transition in frames
.if \n(ll>1 .RE
.nr ll -1

.Pp
An opacity of 0 means that the second stream is fully transparent
(only stream one visible), at 255 stream two is fully opaque.

.Pp
In our case the correct call (transition from stream 1 to stream 2)
would be:

.Pp
\f(CR> transist.flt -o 0 -O 255 -d 25\fP

.Pp
The -s and -n parameters equal to the -o and -f parameters of lav2yuv
and are only needed if anybody wants to render only a portion of the  
transition for whatever reason. Please note that this only affects the
weighting calculations - none of the input is really skipped, so that if you
pass the skip parameter (-s 30, for example), you also need to skip the first
30 frames in lav2yuv (-o 30) in order to get the expected result. If you
didn't understand this, send an email to the authors or simply ignore
-s and -n. The whole procedure will be automated later, anyway.

.Pp

.Pp
Now we want to compress the yuv stream with yuv2lav:

.Pp
\f(CR> yuv2lav -f a -q 80 -o transition.avi\fP

.Pp
Reads the yuv stream from stdin and outputs an avi file (-f a) with
compressed jpeg frames of quality 80.

.Pp
Now we have the whole command for creating a transition:

.Pp
\f(CR> ypipe \(rqlav2yuv -o 255 -f 25 intro.avi\(rq \(rqlav2yuv
-f 25 epilogue.mov\(rq \(br transist.flt -o 0 -O 255 -d 25 \(br yuv2lav -f a -q 80 -o transition.avi\fP

.Pp
The resulting video can be written as a LAV Edit List, a plain text file
containing the following lines:

.Pp
.DS
.sp 
.ft RR
.nf
LAV Edit List
PAL
3
intro.avi
transition.avi
epilogue.mov
0 0 224
1 0 24
2 25 999
.DE
.fi 
.ec
.ft P
.sp

.Pp
This file can be fed into glav or lavplay, or you can pipe it into 
mpeg2enc with lav2yuv or combine the whole stuff into one single mjpeg
file with lavtrans or lav2yuv\(bryuv2lav.

.Pp
Converting the stream to MPEG or DIVx videos


.Pp
First there is some general description in the encoding process, and afterwards
there is a detailed description of some often used output formats. 

.Pp
If you want a one command conversation to mpeg videos try lav2mpeg in
the scripts directory

.Pp
The encoding with the lav2mpeg script lookes like this for mpeg1 output:

.Pp
\f(CR>lav2mpeg -a 160 -b 2110 -d 320x240 -o mpeg1 -O output.mpg file.eli\fP

.Pp
.nr ll +1
.nr t\n(ll 0
.if \n(ll>1 .RS
.nr bi 1
.Pp
Will create a mpeg1 with videobitrate of 2110kBit/sec and audiobitrate of 
160 kBit/sec
.nr bi 1
.Pp
at a resolution of 320x240
.if \n(ll>1 .RE
.nr ll -1

.Pp
Or for the generation of mpeg2 output:

.Pp
\f(CRlav2mpeg -o mpeg2 -O output.mpg file.eli\fP

.Pp
.nr ll +1
.nr t\n(ll 0
.if \n(ll>1 .RS
.nr bi 1
.Pp
Will create a mpeg2 with default bitrate in same resolution as the input
resolution
.if \n(ll>1 .RE
.nr ll -1

.Pp
However, better results can be accomplished by trying out various options
and find out which one works best for you. These are discussed below.

.Pp
The creation of MPEG1 movies is explained with more examples, and with
more details because most things that can be used for MPEG1 also fit 
for the other output formats

.Pp
For the creation of of VCD/SVCD Stills sequences (-f 6, -f 7 in mpeg2enc) you
have to look at:

Still sequences are needed for the creation of menus in VCD/SVCD. The
creation of menus is described in the doku of vcdimager.

.Pp
.SH Creating sound


.Pp
MPEG-1 videos need MPEG1-layer2 sound files. For MPEG-2 videos you can
use MPEG1-Layer2 and MPEG1-Layer3 (MP3).  
But you should stick to MPEG1-Layer2 because most of the MPEG2 players
(DVD Player for example usually the different Winxx Versions have
great problems with this too) are not able to play MPEG2-Video and
MPEG1-Layer3 sound.

.Pp

.Pp
mp2enc is a MPEG layer 2 Audio encoder. The toolame encoder is also able
to produce an layer 2 file. You can use that one as well.
For mp3 creation I'm soure you have an encoder.

.Pp
Example:

.Pp
\f(CR> lav2wav stream.avi \(br mp2enc -o sound.mp2\fP

.Pp
This creates a mpeg sound file out of the stream.avi with 224kBit/sec
bitrate.

.Pp
Example

.Pp
\f(CR> cat sound.wav \(br mp2enc -v 2 -V -o sound.mp2\fP

.Pp
This creates a VCD (-V bitrate=224, stereo, sampling rate:44100)
compatible output from the wav file.

.Pp
With -v 2 mp2enc is more verbose, while encoding you see the number of sec of
audio already encodet.

.Pp
You can test the output with:

.Pp
\f(CR> plaympeg sound.mp2\fP

.Pp
\fBNOTE:\fP plaympeg is a MPEG1 Player for Linux, you can use other players
as well, for MPEG audio testing you can also use mpg123.

.Pp
.SH Converting video


.Pp
You can create MPEG1 and MPEG2 videos.

.Pp
Normally the first video you create is not the best. For optimal
quality/size you need to play with the bitrate, search radius, noise
filter .... The options of mpeg2enc are described in the README in the
mpeg2enc directory. 

.Pp
Example:

.Pp
\f(CRlav2yuv stream.avi stream1.avi \(br mpeg2enc -o video.m1v\fP

.Pp
This creates an video file with the default bitrate of 1152kBit/sec.
This is the bitrate you need if you want to create VCDs. You can specifie more
files, and also use the placeholder %nd. Where \fBn\fP describes
the number.

.Pp
Example:

.Pp
\f(CR> lav2yuv streami%02d.avi \(br mpeg2enc -b 1500 -r 16 -o video.m1v\fP

.Pp

.Pp
mpeg2enc creates a video with a bitrate of 1500kBit/s uses
an search radius of 16. That when trying to find similar 16*16
macroblocks of pixels in between frames the encoder looks up to 16
pixels away from the current position of each block. It looks twice as
far when comparing frames 1 frame apart and so on. Reasonable values
are 16 or 24. The default is 16 so adding the option here is silly.
Lower values (0, 8), improve the encoding speed but you get lower
quality (more visible artifacts), higher values (24, 32) improve the
quality at the cost of the speed. With the file description of
stream%02d.avi all files are proceed that match this pattern beginning
with 00, 01....

.Pp

.Pp
Scaling


.Pp
Using yuvscaler one can now also scale the video before encoding it.
This can be useful for users with a DC10 or DC10+ cards which captures
at -d 1 768x576 or -d 2 384x288 (PAL/SECAM) or -d 1 640x480 (NTSC).

.Pp
You get a full description of all commands reading the man-page or starting:

.Pp
\f(CR>yuvscaler -h\fP

.Pp
Using yuvscaler, you can downscale the video before encoding it. This can
be usefull for, for example, for users with a DC10+ card,  
which captures at 384x288 (PAL/SECAM) when using a  decimation two during
recording. And you want a VCD conform image size which is 352x288 
(for PAL/SECAM).

.Pp
\f(CR> lav2yuv stream.avi \(br yuvscaler -O VCD \(br mpeg2enc -o video.m1v\fP

.Pp
This will rescale the 384x288 or 768x576 (PAL/SECAM) or 352x240 or
640x480 (NTSC) stream to the VCD-size 352x288 (PAL/SECAM) or 352x240
(NTSC) and encode the resulting output YUV data to an mpeg stream. In other
words it will scale nearly every size to the desired output size.

.Pp
It can also do SVCD-scaling to 480x480 (NTSC) or 480x576 (PAL/SECAM):

.Pp
\f(CR> lav2yuv stream.avi \(br
yuvscaler -O SVCD -M BICUBIC \(br mpeg2enc -o video.m1v\fP

.Pp
The mode keyword (-M) forces yuvscaler to use the higher quality
bicubic algorithms for downscaling and not the default resample
algorithms. Upscaling is always done by the bicubic algorithms.

.Pp
Example

.Pp
\f(CR> lav2yuv stream.avi \(br yuvscaler -I USE_450x340+20+30
-O SIZE_320x200 \(br mpeg2enc -o video.m1v \fP

.Pp
Here we only use a part of the input and have special output format.

.Pp
\fBNOTE:\fP yuvscaler can set a active area, and set everything else to
real black using: -I ACTIVE_WidthxHeight+WidthOffset+HeightOffset 

.Pp
Testing is done by:

.Pp
\f(CR> plaympeg video.m1v\fP

.Pp
\fBNOTE:\fPThis are only examples. There are more options you can use. You
can use most of them together to create high quality videos with the
lowest possible bitrate.

.Pp
\fBNOTE2:\fPThe higher you set the search radius the longer the conversion
will take. In common you can say the more options used the longer it takes.

.Pp
\fBNOTE3:\fPMPEG1 was not designed to be a VBR (variable bitrate stream) !!
So if you encode with -q 15 mpeg2enc sets the maximal bitrate -b to
1152. If you want a VBR MPEG1 you have to set -b very high (2500).

.Pp
\fBNOTE4:\fPMaybe you should give better names than video.mpg. A good idea
would be if you see the filename you know the options you've used.
(Ex: \f(CRvideo_b1500_r16_41_21.m1v\fP)
Another possibility is to call all the layer 2 files \(rq\&.mp2\(rq all the
MPEG-1 video files \(rq\&.m1v\(rq and all MPEG-2 video files 
\(rq\&.m2v\(rq Easy to see what's happening then. Reserve .mpg for
multiplexed MPEG-1/2 streams.

.Pp
.SH Putting the streams together


.Pp
Example:

.Pp
\f(CR> mplex sound.mp2 video.m1v -o my_video.m1v\fP

.Pp
Puts the sound.mp2 and the video.m1v stream together to my_video.mpg

.Pp
Now you can use your preferred MPEG player and watch it. All players based
on the SMPG library work well. Other Players are: xmovie, xine, gtv, MPlayer
for example.

.Pp
\fBNOTE:\fPIf you have specified the \fB-S\fP option for mpeg2enc
mplex will automatically split the files if there is in the output filename
a %d (looks like: -o test%d.mpg) The files generated this way
are separate stand-alone MPEG steams!

.Pp
\fBNOTE2:\fPxine might have a problem with seeking through videos.
mplayer has a problem with the \(rqseek backward/forward\(rq with 
variable bitrate streams. Because it goes forward in the file the amount of
data for a constant bitrate stream. And that amount might be significant more
than 10 seconds or one minute. So don't wonder if it seeks much more time
forward or backward than you would expect.

.Pp
\fBVariable bit-rate multiplexing:\fP
Remember to tell mplex you're encoding VBR (-V option) as well as
mpeg2enc (see the example scripts). It *could* auto-detect but it is not
working yet. You should tell mplex a video buffer size at least as large
as the one you specified to \(rqmpeg2enc\(rq Sensible numbers for
MPEG-1 might be a ceiling bit-rate of 2800Kbps, a quality ceiling
(quantization floor) of 6 and a buffer size of 400K.

.Pp
Example:

.Pp
\f(CR> mplex -V -r 1740 audio.mp2 video_vbr.m1v -o vbr_stream.mpg\fP

.Pp
Here we multiplex a variabel bitrate stream. mplex is now a single
pass multiplexer so it can't dedect the maximal bitrate and we have to
specify it. The data rate for the output stream is: audio bitrate +  
peak videobitrate + 1-2% for mplex information. If audio (-b 224) has
224kBit, video has 1500kBit (was encoded with -b 1500 -q 9) then we
have 1724 * 1.01 or about 1740kBit.

.Pp
Example:

.Pp
\f(CR> plaympeg my_video.mpg\fP

.Pp
.SH Creating MPEG1 Videos


.Pp
For MPEG1 you can use mpeg layer 2 Audio and mpeg1 video. A subset of
MPEG1 Movis are VCD's. You can use VBR (Variable BitRate) for the
Video, but the Audio has to be CBR (Constant BitRate).

.Pp
MPEG1 is recomended for picture sizes up to 352x288 for PAL and
352x240 for NTSC for larger sizes MPEG2 is the better choice.
There is no exact line till where MPEG1 is better than MPEG2.

.Pp

.Pp
MPEG1 Audio creation Example


.Pp
\f(CR> lav2wav editlist.eli \(br mp2enc -o sound.mp2\fP

.Pp
This wil fit the MPEG1 quite well. You can save some Bit when telling
to use a lower bitrate (-b option) like 160 or 192 kBit/s

.Pp
\f(CR> lav2wav editlist.eli \(br mp2enc -b 128 -m -o sound.mp2\fP

.Pp
This creates a mono output with an bitrate of 128kBit/sec bitrate.   
The input this time is the editlistfile (can have any name) created  
with glav, so all changes you made in glav are direct processed and   
handed over to mp2enc. So you do NOT have to create an edited stream
with lavtrans to get it converted properly.

.Pp

.Pp
MPEG1 Video creation Example


.Pp
\f(CR> lav2yuv -n 1 editlist.eli \(br mpeg2enc -b 2000 -r 24 -q 6 -o video.m1v\fP

.Pp
There lav2yuv applies a low-pass noise filter to the images. Then
mpeg2enc creates an video with an bitrate of 2000kBit/s (or
2000000Bit/s) but the -q flag activates the variable bitrate and an
quality factor of 6. It uses a search radius of 24.
An editlistfile used.

.Pp
\fBExplanation:\fPwhen mpeg2enc is invoked without the 'q'
flag it creates \(rqconstantbit-rate\(rq MPEG streams. Where (loosely
speaking) the strength of compression (and hence picture quality) is
adjusted to ensure that on average each frame of video has exactly the
specified number of bits. Such constant bit-rate streams are needed for
broadcasting and for low-cost hardware like DVD and VCD players which use
slow fixed-speed player hardware.

.Pp
Obviously this is fairly inefficient as it means inactive scenes use
up bits that could better be \(rqspent\(rq on rapidly changing scenes.
Setting the 'q' flag tells mpeg2enc to generate variable bit-rate
streams. For such streams the bit-rate specified is simply the maximum
permissible. The 'q' parameter specifies the minimum degree of
compression to be applied by specifying how exactly picture
information is recorded. Typically, 'q' would be set so that quiet
scenes would use less than the specified maximum (around 6 or 8) but
fast moving scenes would still be bit-rate limited. For archival
purposes setting a maximum bit-rate high enough never to be reached
(e.g. 10Mbps) and a q of 2 or 3 are reasonable choices.

.Pp

.Pp
Example:

.Pp
\f(CR> lav2yuv stream.avi \(br yuvscaler -I ACTIVE_352x240+0+24
\(br mpeg2enc -b 1152 -r 16 -4 1 -2 1 -o video.m1v\fP

.Pp
Usually there is at the top and at the bottom a nearly black border
and a lot of bandwidth is used for something you do not like. The
yuvscaler -I ACTIVE option sets everything that is not in the
described area to black, but the imagesize (352x288) is not changed.
So you have a real black border the encoder only uses a few bits for
encoding them. You are still compatible to VCD's for this example.
To determine the active window extract one frame to the jpeg format:

.Pp
\f(CR> lavtrans -f i -i 100 -o frame.jpg test.avi\fP

.Pp
Than use your favourite grafic programm to determine the active size.
The -4 1 and -2 1 options improves the quality about 10% but conversion
is slower.

.Pp
At the size of 352x288 (1/2 PAL size, created when using the -d 2 
option when recording) the needed bitrate is/should be between 1000 -
1500kBit/s. For NTSC it should be about the same, because the image is smaller
but there a more frames per second than in PAL.

.Pp

.Pp

.Pp
Anyways, the major factor is quality of the original and the degree of
filtering. Poor quality unfiltered material typically needs a higher
rate to avoid visible artefacts.
If you want to reduce bit-rate without annoying artifacts when
compressing broadcast material you should try the noise filters.

.Pp
Example:

.Pp
\f(CR> lav2yuv stream.avi \(br mpeg2enc -b 1500 -n s -g 6 -G 20 -P -o
video.m1v\fP

.Pp
Here the stream.avi will be encoded with:

.Pp
.nr ll +1
.nr t\n(ll 2
.if \n(ll>1 .RS
.IP "-b 1500"
.nr bi 1

.Pp
a Bitrate of 1500kBit/sec
.IP "-n s"
.nr bi 1

.Pp
the input Video norm is forced to SECAM
.IP "-P"
.nr bi 1

.Pp
This ensures, that ensure 2 B frames appear between adjacent I/P
frames. Several common MPEG-1 decoders can't handle streams where less
than 2 B-frames appear between I/P frames
.IP "-g 6 -G 20"
.nr bi 1

.Pp
the encoder can dynamically size the output streams
group-of-pictures to reflect scene changes. This is done by setting a
maximum GOP (-G flag) size larger than the minimum (-g flag).   
For VCDs sensible values might be a minimum of 9 and a maximum of 15.
For SVCD 9 and 15 would be good values. If you only want to play it   
back on SW player you can use other min-max values.
.if \n(ll>1 .RE
.nr ll -1

.Pp

.Pp
Example

.Pp
\f(CR> lav2yuv stream*.avi \(br mpeg2enc -b 1500 -r 16 -4 1 -2 1
-S 630 -B 260 -o video_n1_1500_r16_41_21_S630_B240.m1v\fP

.Pp
lav2yuv processes all the stream files. Then mpeg2enc uses some
options that make the encoded stream look nicer. Using
\fB-S 630\fP means that mpeg2enc marks the stream so that mplex
generates a new stream every 630MB. One important thing is the use of
the \fB-B\fP option which specifies the non-video (audio and mplex
information) bitrate. The \fB-B\fP value of 260 should be fine for audio   
with 224kBit and mplex information. For further information take a  
look at the encoding scripts in the scripts directory.

.Pp

.Pp
MPEG1 Multiplexing Example


.Pp
Example

.Pp
\f(CR >mplex sound.mp2 video.m1v -o my_video.mpg\fP

.Pp
Puts the sound.mp2 and the video.m1v stream together to my_video.mpg.
It only works that easy if you have CBR (not used the -q option).

.Pp
Example

.Pp
\f(CRmplex -V -r 1740 audio.mp2 video_vbr.m1v -o vbr_stream.mpg\fP

.Pp
Here we multiplex a variable bitrate stream. mplex is now a single
pass multiplexer so it can't detect the maximal bitrate and we have to
specify it. The data rate for the output stream is: \fBaudio bitrate +
peak videobitrate + 1-2% for mplex information\fP\&. If audio (-b 224)
has 224kBit, video has 1500kBit (was encoded with -b 1500 -q 9) then we   
have 1724 * 1.01 or about 1740kBit.

.Pp
.SH Creating MPEG2 Videos


.Pp
MPEG2 is recommended for sources with a greater picture than 352x240
for NTSC and 352x288 for PAL. MPEG2 can also handle interlaced sources
like recording from TV at full resolution.

.Pp
MPEG2 allows the usage of mpeg layer 3 (mp3) sound. So you can use   
your favorite mp3encoder for the creation of the sound. The audio can
also be a VBR Stream.

.Pp
MPEG2 is usually a VBR Stream. MPEG2 creation with optimizing need a
lot of CPU power. But a film with the double resolution does NOT is
not 4 times larger than an MPEG1 Stream. Depending on your quality
settings it will be about 1.5 up to 3 times larger than the MPEG1
Stream at the half resolution.

.Pp
MPEG2 Audio creation Example


.Pp
\f(CR> lav2wav editlist.eli \(br mp2enc -o sound.mp2\fP

.Pp
This will fit the MPEG2 quite well. You can save some Bit when telling
to use a lower bitrate (-b option) like 160 or 192 kBit/s.
I hope I don't need to explain the usage of an MP3 Encoder ?
But you should not use all the fancy options you can use.

.Pp
MPEG2 Video creation Example


.Pp
\f(CR> lav2yuv editlist.eli \(br mpeg2enc -f 3 -b 3000 -q 9
-o video.m2v\fP

.Pp
A very simple example for MPEG2 Video.
The most important option is the -f 3. That tells mpeg2enc that it
should create a MPEG2 stream. Because it is a generic MPEG2 you have
to use the -b bitrate options. And should use the -q option because
you usually want a space saving VBR Stream. When using VBR Streams the
-b option tell mpeg2enc the maximum bitrate that can be used. The -q  
option tell mpeg2enc which quality the streams should have, but is
bound to the maximal bitrate -b we allow.

.Pp
\f(CR> lav2yuv editlist.eli \(br mpeg2enc -f 3 -4 1 -2 1 -q7 -b 4500
-V 300 -P -g 6 -G 18 -I 1 -o video.m2v\fP

.Pp
This is more like a high quality MPEG2 Stream. The -4 1 -2 1 option 
make a bit better quality. With -b 4500 -q 7 you tell mpeg2enc the 
maximal bitrate and the Quality factor. -V is the video buffer size
used for decoding the stream. For SW playback it can be much higher
that the default. Dynamic GOP set with -g -G, A larger GOP size can
help reduce the bit-rate required for a given quality. The -P option
also ensures that 2 B frames appear between adjacent I/P frames. The
-I 1 option tells mpeg2enc that the source is a interlaced material
like videos. There is time consuming interlace-adapted motion
compensation an block encoding done. mpeg2enc will switch to this mode
if the size of the frames you encode is larger than the VCD size for  
you TV Norm.

.Pp
If you denoise the images with yuvdenoise and use the deinterlacing  
(-F) built in there you should tell mpeg2enc that it does not need to 
do motion estimation for interlaced material. You have to set the   
mpeg2enc -I 0 option to tell that the frames are already deinterlaced.
This will save a lot of time when encoding. If you don't do it it will
cause no other drawbacks.

.Pp
You can also use scaling an options that optimize (denoise) the 
images, to get smaller streams. But this options are explained in deep
in the according sections.Which values should be used for VBR Encoding


.Pp
The -q option controls the minimum quantization of the output stream.
Quantization controls the precision with which image information is
encoded. The lower the value the better the image quality.

.Pp
Usually you have to set up a maximum bitrate with the -b option. So
the tricky task is to set a value for the -q option and the -b option
that produces a nice movie without using to much bandwidth and not 
much artefacts.

.Pp
A Quality factor should be chosen that way that the mplex output of
Peak bit-rate and Average bit-rate differ for about 20-25%\&.
If the the difference is very small < 10%, it is very likely
that you have done something wrong. It is very likely the you have chosen the  
wrong values for the maximal bitrate or a to high quality factor.

.Pp
A combination that will produce more artefacts you can count, is a  
SVCD with a maximal video bitrate of 2500kBit and a qualitfactor set
to 1 or 2.
For SVCD with a video limit of 2500kBit a quality factor of 7-11 fits
quite good. If you use filter programs or have a very good source like 
digital TV, DVD like material or rendered pictures. If your SVCD/DVD
player supports higher bitrates than the official 2788kBit/sec for the
video and audio. Use the higher bitrate and a higher quality factor,  
action scenes for example will look much better.

.Pp
The same (7-11) quality factor for a full size picture and a top
bitrate of 3500 to 4000 kBit won't produce to much artefacts too.

.Pp
For SVCD/DVD you can expect a result like the one described if the
maximal bitrate is not set too low:

.Pp

.DS
.sp 
.ft RR
.nf
   q <= 6 real sharp pictures, and good quality
   q <= 8 good quality
   q >= 10 average quality
   q >= 11 not that good
   q >= 13 here even still sequences might look blocky
.DE
.fi 
.ec
.ft P
.sp
Encoding destination TV (interlaced) or Monitor (progressive)


.Pp
MPEG2 supports interlaced movies to be encoded. So a MPEG2 movie can
be interlaced or progressive. It depends on the source Film or
broadcast. And on the viewing device.

.Pp
If you encode a Film both fields should be the same. Deinterlace the
stream with yuvdenose -F, or if you have a high quality source, and  
don't need to use the denoiser, with yuvscaler -O NOT_INTERLACED. Also
set the mpeg2enc interlace-mode (-I) option to 0. This means that
there is no interlacing.
We do here not really need deinterlacing because there is no motion 
between the fields of the frame. We only need to union them to a
single progressive frame.

.Pp
This movie should be played back an any device (TV or Monitor) without
problems.

.Pp
If you have an interlaced source (broadcast) you can encode it as     
interlaced stream. Or deinterlace the stream, and encode it as
progressive stream. If you deinterlace it with yuvdenoise -F, you will
lose details.
But if you plan to play the recorded stream on your DVD player and you
TV. It would not be wise to do that. But if you only want to play it
back on the Monitor (progressive display) the picture lookes better
when playing it back if it is deinterlaced. If the player you use, can
do deinterlacing it does not matter if your encoded video has
interlaced frames or progressive frames.

.Pp
If you plan to deinterlace the stream you can only do this with
yuvdenose -F, and set the mpeg2enc -I 0. If you do not want do
deinterlace th stream, yo do not need to set any special option.(Do
not use yuvscaler -F, and mpeg2enc -I 0)

.Pp
If you like to pause the stream and look on the still you should
deinterlace. Because then the image is flicker free when pausing.

.Pp
If you have a film (progressive) with parts from a broadcast
(interlaced) mixed together. Like in a documentation, where some parts
are from an speaker are recorded interlaced and other parts are filmed.
You have to decide if you want optimal film sequences and good still
images you should deinterlace (yuvdenoise -F, mpeg2enc -I 0).
Else you do not need to deinterlace it, and have a better quality of
the interlaced sequences.

.Pp
MPEG2 Multiplexing Example


.Pp
\f(CR> mplex -f 3 -b 300 -r 4750 -V audio.mp3 video.mp3 -o final.mpg\fP

.Pp
Now both streams are multiplexed, a mp3 audio and a mpeg2 video. You  
have to use the -f 3 option to tell mplex the output format. You also
have to add the -b decoder buffers size with the same value used when 
encoding the video. -r is that rate of video + audio +1-2% of mplex
information.

.Pp
The -V option tells that your source for mplexing is a VBR stream. If
you don't use this option mplex creates something like a CBR Stream
with the bitrate you have told it with the -r option. An this streams 
usually get BIG.

.Pp

.Pp
.SH Creating Video-CD's


.Pp
VCD is a cut down version of MEPG1 streams.
VCD format was defined by Philips. The goal was to use a single speed
CD-drive, and other cheap hardware (=no that flexibel) to have a
rather cheap HW-Player. The spec for VCD has Philips, but they are not
aviable for everyone. Because of that there are some limitations on VCD's.
Like bitrate for video 1152kBit and for audio layer 2 audio with
224kBit stereo. You are not allowed to use the -q option, dynamic GOP
the video buffer is limited to 46kB.
The image size is limited to 352x240 for NTSC, an to 352x288 for PAL.

.Pp
If you have no VCD player, and you plan to play it back on your DVD 
player for example. You DVD player might be that flexible to allow
larger bitrates, dynamic GOP, larger video buffer and so on

.Pp
VCD Audio creation Example


.Pp
\f(CR> lav2wav stream.avi \(br mp2enc -V -o sound.mpg\fP

.Pp
\fB-V\fP force VCD compatible output (same as: -b 224 -r 44100 -s). For
hardware players, you should stick to 44.1 224kBps Stereo layer 2 Audio.

.Pp
VCD Video creation Example


.Pp
\f(CR> lav2yuv stream.avi \(br yuvscaler -O VCD \(br
mpeg2enc -f 1 -r 16 -o video.mpg\fP

.Pp
For a VCD compatible output the -f 1 sets all options in mpeg2enc as
needed. It seems that many VCD players (Avex for example) are not able to
play MPEG streams that are encoded with a search radius greater than 16 so
do not use the -r option to override the default of 16.

.Pp
\f(CR> lav2yuv streams.eli >
mpeg2enc -f 1 -4 1 -2 1 -S 630 -B 260 -P -o video.m1v\fP

.Pp
Using \fB'-S 630'\fP means that mpeg2enc marks the stream so
that mplex generates a new stream every 630MB. One important thing is the use
of the \fB-B\fP option which specifies the non-video (audio and mplex
information) bitrate. The -B value of 260 should be fine for audio
with 224kBit and mplex information. For further information take a   
look at the encoding scripts in the scripts directory. So the
multiplexed streams should easily fit on a CD with 650MB.

.Pp
The default value (-B) is 700MB for the video. mpeg2enc marks
automatically every stream at that size if the -B option does not set
anything else. If you have a CD where you can write more MB like 800,
you have to set the -S option else mpeg2enc will mark the stream at
700 MB, and mplex will split the stream there. Which might not be what
you want.

.Pp

.Pp

.Pp
VCD Multiplexing Example


.Pp
\f(CR> mplex -f 1 sound.mpg video.mpg -o vcd_out.mpg\fP

.Pp
The -f 1 option turns on a lot of weird stuff that otherwise has no
place in a respectable multiplexer!

.Pp
Creating the CD


.Pp
The multiplexed streams have to be converted to an VCD compatible.  
This is done by vcdimager

.Pp

.Pp
\f(CR> vcdimager testvideo.mpg\fP

.Pp
Creates a \fBvideocd.bin\fP, the data file, and a \fBvideocd.cue\fP
which is used as control file for cdrdao.

.Pp
You use cdrdao to burn the image. Cdrdao is yet another fine
Sourceforge project which is found at:

.Pp
Notes


.Pp
For MPEG-1 encoding a typical (45 minute running time) show or 90 odd
minute movie from an analog broadcast a constant bit-rate of around
1800 kBit/sec should be ideal. The resulting files are around 700M for
45 minutes which fits nicely as a raw XA MODE2 data track on a CD-R.
For pure digital sources (DTV or DVD streams and similar) VCD 1152
works fine.

.Pp
\fBNote:\fP If you encode VBR MPEG1 (-q) remember the Hardware was
probably not designed to do the playback because it is not in the
specifications. If it works be very happy. I've notices that it helps
when you have an MPEG1 Stream to tell vcdimager that it is an SVCD.
vcdimager complains (but only with a warning and not a fatal error)but
you should be able to burn it. This could convince the player to use
an other firmware and play it back correct, but there is no guarantee
for that.

.Pp
Storing MPEGs


.Pp
If you record the data as XA mode 2 tracks you can fit appreciably
more on a CD (at the expense of error correction/detection). You can
use vcdimager to do this and vcdxrip (part of the vcdimager package)
to extract (\(rqrip\(rq) the resulting files. For better Quality
there are SVCD and XVCD and DVD.

.Pp
Currently only SVCD is fully supported with a pre-set format in mplex
and tools to create disks. MPEG streams that can be played by DVD
player hardware and software can readily produced using mpeg2enc/mplex
but there is currently no means to make a properly structured disk image.

.Pp
If your player doesn't support SVCD you may well find it can handle
VCD streams that have much higher than standard bit-rates. Often as
much as 2500kBit/sec is possible. The AudioVox 1680 for example can
handle 2500kBit/s VCD rates (it also handles VCDs with VBR MPEG-1 but
other players might not be so forgiving).
With higher bit-rates and good quality source material it is worth
trying mpeg2enc's -h flag which produce a stream that is as sharp as
the limits of the VCD standard permits.
The -h flag seems to help also if there is a low quality stream, the
video does not look that sharp using the flag, but there are not that
much glitches as without it.

.Pp
However, if your player supports it and you have the patience for the
much longer encoding times SVCD is a much better alternative. Using a
more efficient MPEG format SVCD more than doubles VCD's resolution
while typically producing files that are rather less than twice as big.
.SH Creating SVCD


.Pp
SVCD is a cut down version of MEPG2 streams. SVCD format was defined
by Philips. The spec for SVCD has Philips, but they are not aviable for
everyone. Record at full TV resolution (means: -d 1 for PAL this is 720x576)
The resolution is for NTSC is 480x480 of PAL 480x576, so you know why you
should record at full size.

.Pp
SVCD Audio creation Example


.Pp
\f(CR> lav2wav stream.avi \(br mp2enc -V -o sound.mp2\fP

.Pp
The SVCD specifications permit a much wider choice of audio rates,
it is not necessary to use 224 kBit/sec. Any audio rate between
32 and 384 kBit/sec is permitted. The audio may be VBR (Variable Bit
Rate).

.Pp
SVCD Video creation Example


.Pp
\f(CR> lav2yuv stream.avi \(br yuvscaler -O SVCD \(br mpeg2enc -f 4 -q 7 -I 1 -V 200 -o video.m2v\fP

.Pp
.nr ll +1
.nr t\n(ll 2
.if \n(ll>1 .RS
.IP "-f 4"
.nr bi 1

.Pp
sets the options for mpeg2enc to SVCD
.IP "-q 7"
.nr bi 1

.Pp
tell mpeg2enc to generate a variable bitrate stream
.IP "-I 1"
.nr bi 1

.Pp
tell mpeg2enc to assume that the original signal is field
interlaced video where the odd rows of pixels are sampled a half frame
interval after the even ones in each frame. The -I 0 (progressive
output (no field pictures)) option will also work for PAL
.if \n(ll>1 .RE
.nr ll -1

.Pp
You can use lower bitrates, but the SVCD standard limits \fBtotal
bit-rate (audio and video) to 2788800 Bit/sec\fP\&. So with 224Kbps audio
and overheads 2550 may already be marginally too tight. Since the SVCD
format permits any audio rate between 32 and 224 kBit/sec you can save
a few bits/sec by using 192k audio.

.Pp
SVCD supports variable bitrate (VBR), because MPEG2 is usually VBR,
but with the top video bitrate limit of 2500kBit/sec. With the -f 4
flag the encoder also sets dynamic GOP with a low limit of -g 6 and a
high limit of -G 18. This saves a few bits/sec and improves the
picture quality during scene changes.
When encoding with -f 4 mpeg2enc ignores the video bitrate (-b) and   
search radius (-r) options. If you use -f 5 mpeg2enc uses this options.

.Pp
An other possibility for movies in PAL (European style 25 frames/50
fields per sec) video is:

.Pp
\f(CR> lav2yuv stream.avi \(br yuvscaler -O SVCD \(br
mpeg2enc -f 4 -I 0 -V 300 -o video.m2v\fP

.Pp
Movies are shot on film at 24 frames/sec. For PAL broadcast the film is
simply shown slightly \(rqtoo fast\(rq at 25 frame/sec (much to the
pain of people with an absolute pitch sense of pitch). The -I 0 flag turns 
off the tedious calculations needed to compensate for field
interlacing giving much faster encoding.

.Pp
Unfortunately, movies broadcast in NTSC (US style 30 frames/60 fields
sec) video this will produce very poor compression. The \(rqpulldown\(rq  
sampling used to produce 60 fields a second from a 24 frame a second  
movie means half the frames in an NTSC *are* field interlaced.

.Pp

.Pp
Don't forget the -S and -B options mentioned above. You want that the
stream fits on the CD don't you ?

.Pp
SVCD Multiplexing Example


.Pp
\f(CR> mplex -f 4 -b 300 -r 2750 sound.mp2 video.m2v -o svcd_out.mpg\fP

.Pp
.nr ll +1
.nr t\n(ll 2
.if \n(ll>1 .RS
.IP "-f 4"
.nr bi 1

.Pp
tells mplex to mplex a SVCD
.IP "-r 2750"
.nr bi 1

.Pp
is the calculated Audio + Video Bitrate + 1-2% multiplex
information
.IP "-b 300"
.nr bi 1

.Pp
is the Buffer aviable on the playback device, the same used
for the video encoding (there the -V option)
.if \n(ll>1 .RE
.nr ll -1

.Pp
SVCD Creating the CD


.Pp
Example:

.Pp
\f(CR> vcdimager -t svcd testvideo.mpg\fP

.Pp
Creates a \fBvideocd.bin\fP, the data file, and a \fBvideocd.cue\fP
which is used as control file for cdrdao.

.Pp
Use cdrdao to burn the image as mentioned earlier.

.Pp
\fBNOTE:\fPIf you want to build \(rqcustom\(rq VCD/SVCD you will
need to use the mplex -f 2 and -f 5 switches.

.Pp
\fBNOTE:\fPThe VCD SVCD stuff may work on your HW player or not. There
are many reports that it works quite well. Don't be worried if it does
not work. Nor am I responsible for unusable CDs. (\(rqcoasters\(rq)
.SH Creating DIVX Videos


.Pp
The yuv2divx in the mjpeg tools uses the codecs of the avifile library
to generate videos. The output formats you can create are dependent on
the avifile version you use. It is recommended that you use at least
version 0.6 of avifile. (Some distributions come with avifile-0.53, which
is no longer supported by the avifile maintainers.)

.Pp
The prossesing is a little bit different because the audio and video
files do not need to be multiplexed afterwards. The output is created
in a single pass. You can use the normal video encoding process. The
audio file, or the sound that is already in the recorded avi, has to
be given yuv2divx as an option. You can specify a WAV file, an edit
list, or, as in this case, the same file we're getting the video from.

.Pp
Enough talk here is an example:

.Pp
\f(CR> lav2yuv stream.avi \(br yuv2divx -A stream.avi -o lowrate.avi\fP

.Pp
Looks a bit strange because yuv2divx reads the YUV video stream from
stdin but has the audio passed in by an option. The -A specifies the
audio stream. In this case, it is also in our stream.avi. The output
is also a .avi file because Divx is also named avi. The .divx
extension is also sometimes used.

.Pp
Example:

.Pp
\f(CR> lav2yuv stream.avi \(br yuvdenoise \(br yuvscaler -O SIZE_640x480 \(br yuv2divx -b 2500 -a 196 -E DIV5
-A stream.avi -o output.avi\fP

.Pp
You see that using other tools to get the stream in the proper form is
no problem. Here we set the maximum bitrate to 2500kBit/s, and the  
audio bitrate to 192kBit/s. The video coded this time used is the DIV5.

.Pp
A bitrate of 2500 is considered rather high for Divx encoding. Divx
encoding offers its greatest utility (giving decent images at high
compression) at bitrates that MPEG2 encoding would generate poor
quality. Experimentation is encouraged, of course, but the general  
rule of thumb appears to be that Divx offers similar quality at
two-thirds of the bitrate of MPEG2 -- note that this is video bitrate 
only, audio bitrate remains the same as the same type of encoding is
used for both.

.Pp
lav2divx


.Pp
If you do not need to perform any audio or video alteration of the
audio or video streams, you can perform a conversion to divx in one 
step using the lav2divx utility.

.Pp
\f(CR> lav2divx -b 1000 -E DIV5 -o output.avi input.editlist\fP

.Pp
This takes the edit list and uses that as the source for both the
video and the audio. Since it's all done in one step, there's no
opportunity to use any of the YUV filters, scalers, and denoisers.

.Pp
A word on avifile codecs


.Pp
The lav2divx and yuv2divx utilities are primarily intended for
creating Divx avi files. However, since they use avifile, it's   
possible to generate output in any video format avifile is aware of. You
specify the codec by its four letter code (\(rqDIV5\(rq in the examples
above, this is sometimes called the codec's \(rqfourcc\(rq).
The ones that are available vary greatly depending on the specific libraries
available to avifile.Optimizing the stream


.Pp
Using filters helps to increase the image quality using fixes bitrate
video streams. With VBR (variable bit rate) video the filesize is reduced.

.Pp
Example

.Pp
\f(CR> lav2yuv stream.avi \(br yuvmedianfilter \(br
mpeg2enc -o video.m1v\fP

.Pp
Here the yuvmedianfilter program is used to improve the image. This 
removes some of low frequence noise in the images. It also sharpens
the image a little. It takes a center pointer avg the pixels around it
that fall with the threshold. It then replaces the center pixel with
this new value.
You can also use the -r (radius) option for an other search radius.
Use -t to control the threshold of the pixel count in the avg.  
The defaults -r 2 and -t 2 look good

.Pp
Example

.Pp
\f(CR> lav2yuv stream.avi \(br yuvdenoise \(br mpeg2enc -o video.m1v\fP

.Pp
Now we are using yuvdenoise to improve the image. The filter mainly
reduces color and luminance-noise and flickering due to phase errors.
If you want yuvdenoise also to deinterlace the stream use the -F option.

.Pp
Example

.Pp
\f(CR> lav2yuv stream.avi \(br yuvkineco -F 1 \(br mpeg2enc -o video.m1v\fP

.Pp
yuvkineco is used for NTSC sources. It does the conversation from
30000.0/1001.0 (about 29.97) fps to 24000.0/1001.0 (about 23.976) fps, you
can call it \(rqreverse 2-3 pulldown\(rq more info about this in the
README.2-3pulldown. yuvkineco does only remove NTSC specific problems.

.Pp
If you want to improve the image you should also use yuvdenoise:

.Pp
\f(CR> lav2yuv stream.avi \(br yuvkineco \(br yuvdenoise \(br mpeg2enc -o video.m1v\fP

.Pp
Example

.Pp
\f(CR> lav2yuv stream.avi \(br yuvycsnoise \(br mpeg2enc -o video.m1v\fP

.Pp
yuvycsnoise is also used for NTSC and is specialized for NTSC Y/C
separation noise. If video capture hardware has only a poor Y/C
separator then at vertical stripes (especially red/blue) noises appear
which seem checker flag and bright/dark invert per 1 frame.
yuvycsnoise reduces noises of this type. You can also use different
thresholds for luma/chroma and the optimizing method.

.Pp
yuvycsnoise works only correct when we have NTSC with:

.Pp
.nr ll +1
.nr t\n(ll 0
.if \n(ll>1 .RS
.nr bi 1
.Pp
full height (480 lines)
.nr bi 1
.Pp
full motion captured (29.97 fps)
.nr bi 1
.Pp
captured with poor Y/C separator hardware
.if \n(ll>1 .RE
.nr ll -1

.Pp

.Pp
For more information about the yuvkineco and yuvycsnoise read the
README in the yuvfilters directory.

.Pp
If you want to know now the optimal settings for the denoiser, scaler
and so on. Replace the mpeg2enc or yuv2divx with yuvplay. yuvplay
playes back the yuv frames. So you can see if the options you have
choosen are making the thing better or worse.

.Pp
A command would look like this:

.Pp
\f(CR> lav2yuv stream.eli \(br yuvdenoise -options \(br
yuvscaler -options \(br yuvplay\fP

.Pp
If you are looking for a hardware device that can make the vide to look
better before you record it. We currently know about two firms that produce
such boxes. 

.Pp
One produced by SIMA: , that device will work with NTSC.
And a one other produced by ELV (german distributor): 

there you find in the SHOP area, a section where you can take a look at
their Video - Audio devices. Most of that devices work only with PAL.Transcoding of existing MPEG-2


.Pp
For transcoding existing MPEG-2 streams from digital TV cards or
DVD a still lower data-rate than for broadcast will give good results.
Standard VCD 1152 Kbps typically works just fine for MPEG1. The
difference is in the Signal/Noise ratio of the original. The noise in 
the analog stuff makes it much harder to compress.

.Pp
You will also need to manually adjust the audio delay offset relative to
video when multiplexing. Very often around 150ms delay seems to do
the trick.

.Pp
You have to download the ac3dec and mpeg2dec packages. You can find
them at mjpeg homepage ( 
).
You also need sox and toolame.

.Pp
In the scripts directory there is a \fBmpegtranscode\fP script that
does most of the work.

.Pp
So transcoding looks like this:

.Pp
\f(CR> mjpegtranscode -V -o vcd_stream mpeg2src.mpg\fP

.Pp
.nr ll +1
.nr t\n(ll 2
.if \n(ll>1 .RS
.IP "-V"
.nr bi 1

.Pp
set's the options so that a VCD compatible stream is generated
.IP "-o vcd_stream"
.nr bi 1

.Pp
a vcd_stream.m1v (video) and vcd_stream.mp2 (audio) is
created
.IP "mpeg2src.mpg"
.nr bi 1

.Pp
specifies the source stream
.if \n(ll>1 .RE
.nr ll -1

.Pp

.Pp
The script prints also something like this:

.Pp
\f(CR> SYNC 234 mSec\fP

.Pp
You will need to adjust the audio/video startup delays when
multiplexing to ensure audio and video are synchronized.
The exact delay (in milliseconds) that you need to pass to mplex to
synchronize audio and video using the \(rq-v\(rq\&" is printed by the
extract_ac3 tool labeled \(rqSYNC\(rq when run with the
\(rqs\(rq flag. This is the value th mjpegtranscode script prints out
after the \fBSYNC\fP word.

.Pp
Then you need to multiplex them like this:

.Pp
\f(CR> mplex -f 1 -O 234 vcd_stream.mp2 vcd_stream.m1v -o lowrate.mpg\fP

.Pp
.nr ll +1
.nr t\n(ll 2
.if \n(ll>1 .RS
.IP "-f 1"
.nr bi 1

.Pp
Mux format is set to VCD
.IP "-O 234"
.nr bi 1

.Pp
Video timestamp offset in mSec, generated by the mjpegtranscoding
script, there negative values are allowed
.IP "vcd_stream.mp2 & vcd_stream.m1v"
.nr bi 1

.Pp
generated files by the script
.IP "lowrate.mpg"
.nr bi 1

.Pp
the VCD compatible output stream
.if \n(ll>1 .RE
.nr ll -1

.Pp
Here we have a SVCD (MPEG-2 video) example:

.Pp

.Pp
\f(CR> mjpegtranscode -S -o svcd_stream mpeg2src.mpg\fP

.Pp
You have to multiplex it with:

.Pp
\f(CR> mplex -f 4 -O 234 svcd_stream.mp2 svcd_stream.m2v -o lowrate.mpg\fP

.Pp
\fBProblem:\fP
There is sometimes a problem with NTSC and VCD playback because movies
may be recoded with 3:2 pulldown NTSC with 60 fields/sec. mpeg2dec is
designed for playback on computers and generates the original
24frames/sec bitrate. If you encode the video now 30frames/sec video
is created. This video is now much too short for the encoded audio.

.Pp
The transcoding can be made to work but it must be done manually:

.Pp
\f(CR> cat mpeg2src.mpg \(br mpeg2dec -s -o YUVs \(br
mpeg2enc -I 0 -f 4 -q 9 -V 230 -p -P -o svcd_stream.m2v\fP

.Pp
The -p tells mpeg2enc to generate header flags for 3:2 pull down of
24fps movie. It may also work if you do not add the -p flag.
You do not need the -p flag when transcoding to VCD format because it
is not supported in mpeg1.
.SH If you want to do every step on your own it has to look like this


.Pp
Extracting Audio:

.Pp
\f(CR> cat test2.mpg \(br extract_ac3 - -s \(br ac3dec -o wav -p sound.wav 2>/dev/null\fP

.Pp
One of the first lines showed contains the label \(rqSYNC\(rq you
have to use this time afterwards for the multiplexing. The 2>/dev/null
redirects the output of ac3dec to /dev/null.  
In the next step you generate the mpeg audio file:

.Pp
\f(CR> cat sound.wav \(br mp2enc -V -v 2 -o audio.mp2\fP

.Pp
.nr ll +1
.nr t\n(ll 2
.if \n(ll>1 .RS
.IP "-V"
.nr bi 1

.Pp
forces VCD format, the sampling rate is converted to 44.1kHz from 48kHz
.IP "-v 2"
.nr bi 1

.Pp
unnecessary but if you use it mp2enc tells you how many seconds
of the audio file are already encoded.
.IP "-o"
.nr bi 1

.Pp
Specifies the output file.
.if \n(ll>1 .RE
.nr ll -1

.Pp
cat test2.mpg \(br extract_ac3 - -s \(br ac3dec -o wav \(br
sox -t wav /dev/stdin -t wav -r 44100 /dev/stdout \(br toolame -p 2 -b 224 
/dev/stdin audio.mp2

.Pp
This should you command look like when you want to use \fBtoolame\fP\&.
One of the first lines again output contains the label \(rqSYNC\(rq\&.
You have to use this time (referred to as \&"SYNC_value\&" below) when doing the 
multiplexing.

.Pp
You can generate VCD and SVCD videos, and own mpeg1/2 videos.

.Pp
For VCD creation use:

.Pp
\f(CR> cat test2.mpg \(rq mpeg2dec -s -o YUVh \(rq
mpeg2enc -s -o video_vcd.m1v\fP

.Pp
.nr ll +1
.nr t\n(ll 2
.if \n(ll>1 .RS
.IP ""
.nr bi 1

.Pp
mpeg2dec:
.IP "-s"
.nr bi 1

.Pp
tells mpeg2dec to use program stream demultiplexer
.IP "-o YUVh"
.nr bi 1

.Pp
the output size of the extracted frames.
.if \n(ll>1 .RE
.nr ll -1

.Pp
There are other output modes, try \(rqmpeg2dec --help\(rq but the
most important here are:

.Pp
.nr ll +1
.nr t\n(ll 2
.if \n(ll>1 .RS
.IP "YUV"
.nr bi 1

.Pp
is the full image size, unscaled
.IP "YUVs"
.nr bi 1

.Pp
is SVCD size, it can only scale down to 2/3 of the original size 
.IP "YUVh"
.nr bi 1

.Pp
is VCD size, or about the half of the original size
.if \n(ll>1 .RE
.nr ll -1

.Pp
Mplex with:

.Pp
\f(CR> mplex -f 1 -O SYNC_value audio.mp2 video_vcd.m1v -o vcd_stream.mpg\fP

.Pp
.nr ll +1
.nr t\n(ll 2
.if \n(ll>1 .RS
.IP "-f 1"
.nr bi 1

.Pp
generates an VCD stream
.IP "-O SYNC_value"
.nr bi 1

.Pp
the value mentioned aboth
.if \n(ll>1 .RE
.nr ll -1

.Pp

.Pp
For SVCD creation use:

.Pp
\f(CR> cat test2.mpg \(br mpeg2dec -s -o YUVs \(br
mpeg2enc -f 4 -q 9 -V 230 -o video_svcd.mpg\fP

.Pp
.nr ll +1
.nr t\n(ll 2
.if \n(ll>1 .RS
.IP "-q 9"
.nr bi 1

.Pp
Quality factor for the stream (VBR stream) (default q: 12)
.IP "-V 230"
.nr bi 1

.Pp
Target video buffer size in KB
.IP "-o"
.nr bi 1

.Pp
Output file
.if \n(ll>1 .RE
.nr ll -1

.Pp
Mplex with:

.Pp
\f(CR> mplex -f 4 -b 230 audio.mp2 video_svcd -o svcd_stream.mpg\fP

.Pp
.nr ll +1
.nr t\n(ll 2
.if \n(ll>1 .RS
.IP "-f 4"
.nr bi 1

.Pp
generate an SVCD stream
.IP "-b 200"
.nr bi 1

.Pp
Specify the video buffer also used while video encoding
.if \n(ll>1 .RE
.nr ll -1

.Pp
For other video output formats this might work:

.Pp
\f(CR> cat test2.mpg \(br mpeg2dec -s -o YUV \(br
yuvscaler -O SIZE_320x200 -O NOT_INTERLACED \(br
mpeg2enc -o strange_video.m1v\fP

.Pp
If you want to reedit mpeg streams, this also works, but in a slightly
different way. For demultiplexing you can use bbdmux, from the bbtools
package. Splits out either video or audio very cleanly. 
You can't get it any more from the hompage from Brent Beyler, it can
still be found when you search for it using that keywords \(rq
bbtools linux -suse -blackbox\(rq\&. Currenty it can be found at:

.Pp

.Pp
First run:

.Pp
\f(CR> bbdmux myvideo.mpg\fP

.Pp
You should get something like this:

.Pp
.DS
.sp 
.ft RR
.nf
Found stream id 0xE0 = Video Stream 0
Found stream id 0xC0 = MPEG Audio Stream 0
Found stream id 0xBE = Padding Stream
.DE
.fi 
.ec
.ft P
.sp

.Pp
Extract audio with:

.Pp
\f(CR> bbdmux myvideo.mpg 0xC0 audio.mp1\fP

.Pp
Convert it to wav:

.Pp
\f(CR> mpg123 -w audio.wav audio.m1v\fP

.Pp
Extract video with:

.Pp
\f(CR> bbdmux myvideo.mpg 0xE0 video.m1v\fP

.Pp
Converting video to an mjpeg avi stream:

.Pp
\f(CR> cat video.m1v \(br mpeg2dec -o YUV \(br
yuv2lav -f a -o test.avi\fP

.Pp
Then adding the sound to the avi:

.Pp
\f(CR> lavaddwav test.avi audio.wav final.avi\fP

.Pp
If the source video has already the size of the target video use -o
YUV. Using YUVh makes the video the half size!
The rest can be done just like editing and encoding other streams.
If you have videos with ac3 sound you only have to adapt the commands
above.

.Pp
Extracting Audio:

.Pp
\f(CR> cat test2.mpg \(br extract_ac3 - -s \(br
ac3dec -o wav 2>dev/null >sound.wav\fP

.Pp
Extract video:

.Pp
\f(CR> cat test2.mpg \(br mpeg2dec -s -o YUVh \(br
yuv2lav -f a -q 85 -o test.avi\fP

.Pp
Adding the sound:

.Pp
\f(CR> lavaddwav test.avi sound.wav fullvideo.avi\fP

.Pp
\fBNOTE:\fPYou need much disk space. 1GB of video has a size of about 2GB
at SVCD format and of course disk space is needed for some temp files.
Converting the Video to mjpeg also takes some time.
On my Athlon 500 I never get more than 6-7 Frames a second.
You loose quality each time you convert a stream into an other format! Trading Quality/Speed


.Pp
If absolute quality is your objective a modest improvement can be
achieved using the -4 and -2 flags.
These control how ruthlessly mpeg2enc discards bad looking matches
between sections of adjacent frames during the early stages of the
search when it is working with 4*4 and 2*2 clusters of pixels rather
than individual pixels. Setting -4 1 -2 1 maximizes quality. -4 4 -2 4
maximizes speed. Note that because the statistical criteria mpeg2enc
uses for discarding bad looking matches are usually fairly reliable
the increase/decrease in quality is modest (but noticeable).

.Pp
Reducing the radius of the search for matching sections of images also
increases speed. However due to the way the search algorithm works the
search radius is in effect rounded to the nearest multiple of 8.
Furthermore, on modern CPU's the speed gained by reducing the radius
below 16 is not large enough to make the marked quality reduction
worthwhile for most applications.
.SH Creating streams to be played from disk using Software players


.Pp
Usually MPEG player software is much more flexible than the hardware
built into DVD and VCD players. This flexibility allows for
significantly better compression to be achieved for the same quality.
The trick is to generate video streams that use big video buffers
(500KB or more) and variable bitrate encoding (the -f, -q flag to 
mpeg2enc). Software players will often also correctly play back the   
much more efficient MPEG layer 3 (yes, \(rqMP3\(rq audio format.
A good Mp3 encoder like lame will produce results comparable to layer 2 at
224Kbps at 128Kbps or 160Kbps.SMP and distributed Encoding


.Pp
The degree to which mpeg2enc tries to split work between concurrently
executing threads is controlled by the -M oder --multi-thread [0..32]
option. This optimizes mpeg2enc for the specified number of CPUs. By
default (-M 1), mpeg2enc runs with just a little multi-threading: 
reading of frames happens concurrently with compression. This is done
to allow encoding pipelines that are split across several machines  
(see below) to work efficiently without the need for special buffering
programs.
If you are encoding on a single-CPU machine where RAM is tight you may
find turning off multithreading altogether by setting -M 0 works
slightly more efficiently.

.Pp
For SMP machines with two ore more processors you can speed up
mpeg2enc by setting the number of concurrently executing encoding
threads's you wish to utilize (e.g. -M 2). Setting -M 2 or -M 3 on a
2-way machine should allow you to speed up encoding by around 80%\&.

.Pp
Obviously, if your encoding pipeline contains several filtering stages
it is likely that you can keep two or more CPU's busy simultaneously
even without using -M. Denoising using yuvdenoise is particular
demanding and uses almost as much processing power as MPEG encoding.

.Pp
It you more than one computer you can also split the encoding pipeline
between computers using the standard 'rsh' or 'rcmd'
remote shell execution commands. For example, if you have two computers:

.Pp

.Pp

.Pp
\f(CR> rsh machine1 lav2yuv \(rqmycapture.eli \(br
yuvscaler -O SVCD \(br yuvdenoise\(rq \(br
mpeg2enc -f 4 -o mycapture.m2vi\fP

.Pp
Here the computer where you execute the command is doing the MPEG
encoding whilst \(rqmachine1\(rq is the machine that is decoding
scaling and denoising the captured video.

.Pp
Obviously, for this to work \(rqmachine1\(rq has to be able to
access the video and the computer where the command is executed has to have
space for the encoded video. In practice, it is usually well worth setting
up network file-storage using \(rqNFS\(rq or other packages if you are
going to do stuff like this.
If you have three computers you can take this a stage further, one
computer could do the decoding and scaling, the next could do
denoising and the third could do MPEG encoding:

.Pp
\f(CR> rsh machine1 \(rqlav2yuv mycapture.eli \(br
yuvscaler -O SVCD\(rq \(br
yuvdenoise \(br rsh machine3 mpeg2enc -f 4 -o mycapture.m2v\fP

.Pp
\fBNOTE:\fPHow the remote command executions are set up so that the
data is sent direct from the machine that produces it to the machine that   
consumes it.

.Pp
In practice for this to be worthwhile the network you are using must  
be fast enough to avoid becoming a bottleneck. For Pentium-III class
machines or above you will need a 100Mbps Ethernet.

.Pp
For really fast machines a switched 100MBps Ethernet (or better!) may
be needed.Setting up the rshd (\(rqRemote SHell Daemon\(rq needed for
rsh to do its work and configuring \(rqrsh\(rq is beyond the scope of
this document, but its a standard package and should be easily installed
and activated on any Linux or BSD distribution.

.Pp
Be aware that this is potentially a security issue so use with care on
machines that are visible to outside networks!Interoperability


.Pp
Quicktime files capturing using lavrec can be edited using Broadcast2000.
But Broadcast2000 is not aviable any more on heroinewarrior. 
mjpeg AVI files captured using the streamer tool from the xawtv
package can be edited and compressed and played back using software.
Hardware playback is not possible for such files due to limitations in
the Zoran hardware currently supported. Videos recorded with

can also be processed with the mjpeg tools.

.Pp

.Pp
MPEG files produced using the tools are know to play back correctly on:

.Pp
.nr ll +1
.nr t\n(ll 0
.if \n(ll>1 .RS
.nr bi 1
.Pp
dxr2 (hardware decoder card)
.nr bi 1
.Pp
xine 
.nr bi 1
.Pp
oms 
.nr bi 1
.Pp
dvdview 
.nr bi 1
.Pp
xmovie 
.nr bi 1
.Pp
mplayer 
.nr bi 1
.Pp
vlc 
.nr bi 1
.Pp
MPEG1 only: mtv 
.nr bi 1
.Pp
MPEG1 only: gtv 
.nr bi 1
.Pp
MS Media player version 6 and 7
.nr bi 1
.Pp
SW DVD Player
.if \n(ll>1 .RE
.nr ll -1

.Pp
To find out what you HW-player (most of the time DVD player) can do
take a look at:

.Pp
It seems that the MS Media player likes MPEG-1 streams more if you
have used -f 1 when multiplexing.

.Pp
If you have any problems or suggestions feel free to mail me (Bernhard
Praschinger): 
There is a lot of stuff added from the HINTS which Andrew Stevens (

) created. Wolfgang Goeller checked the document for bugs and spelling
mistakes.

.Pp
And there a some people that helped me with program descriptions and
hints, \fBthanks\fP
.SH "SEE ALSO"
.br 
.LP 
The mjpeg homepage is at:
.br 
http://mjpeg.sourceforge.net/
.br 
http://sourceforge.net/projects/mjpeg

vcdimager  is aviable at: 
.br 
http://www.vcdimager.org/
.br 

cdrdao   is aviable at:
.br 
http://cdrdao.sourceforge.net/index.html
.br 

Linux Video Studio is aviable at:
.br 
http://ronald.bitfreak.net

The lavtools:
.br 
.BR jpeg2yuv(1),
.BR lav2wav(1),
.BR lav2yuv(1),
.BR lavpipe(1),
.BR lavplay(1),
.BR lavrec(1),
.BR lavtrans(1),
.BR mp2enc(1),
.BR mpeg2enc(1),
.BR mplex(1),
.BR ppmtoy4m (1),
.BR yuv2lav(1),
.BR yuvdenoise(1),
.BR yuvkineco(1),
.BR yuvmedianfilter(1),
.BR yuvplay(1),
.BR yuvscaler(1),
.BR yuvycsnoise(1),
.BR y4mcolorbars(1),
.BR y4mtoppm(1).

.br
Tools without a man page: lavaddwaw, glav

