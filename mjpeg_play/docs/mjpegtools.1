.\" 
.TH "MJPEG tools" "1" "2 June 2001" "MJPEG Linux Square" "MJPEG tools manual"
.SH "NAME"
.LP 
.br 
mjpegtools \- MJPEG capture/editting/replay and MPEG encoding toolset.
.br 

.SH "SYNOPSIS"
.LP 
.BR lav * " \-h"
prints out a command synopsis
.br 
.BR yuv * " \-h"
prints out a command synopsis
.br 
.BR mpeg2enc | mp2enc\ \-?
print out a command synopsis
.br 

.SH "DESCRIPTION"
.br 
The mjpetools are a set of programs that can do recording,
playback,  editing and eventual MPEG compression of
audio and video under Linux.  

Although primarily intended for use with capture / playback boards
based on the Zoran ZR36067 MJPEG codec chip the mjpegtools can easily
be used to process and compres MJPEG video streams captured using
xawtv or bcast2000 using simple frame\-buffer devices.


.SH "INTRODUCTION"
.br 

This isn't really a man page (yet).  Its a modified version of the
HOWTO for the tools intended to give an an introduction to the
MJPEG\-tools and the creation of MPEG 1/2 videos. VCD and SVCD, and
the transcoding of existing mpeg streams.

For more information about the programms read the corresponding manpage. You find mor information about the other man pages in the SEE ALSO section.

You will usually have to load the drivers for the Buz or DC10(+) or LML33
cards. So you have to run the update script providing as option the name 
of your card you have. The script is usually in /usr/src/driver\-zoran/

If you compile the tools on a P6 based computer (PPro, P\-II, P\-III, P\-4,
Athlon,Duron) then never try to let them run on a P5 based computer 
(Pentium, Pentium\-MMX, K6, K6\-x, Cyrix, Via, Winchip). You'll get a 
"illegal instruction" and the programm won't work.

Start xawtv to see if you get an picture. If you want to use HW\-playback of
the recorded streams you have to start xawtv (any TV application works) 
once to get the streams played back. You should also check the settings of 
your mixer in the sound card.

Never try to stop or start the TV application when lavrec runs. If you start
or stop the TV application lavrec will stop recording, or your computer could
get "frozen".

One last thing about the data you get before we start:
.br
Audio: ( Samlperate * Channels * Bitsize ) / (8 * 1024)
.br
CD Quality : (44100 Samples/sec * 2 Chanels * 16 Bit ) / (8 * 1024) = 172,2 kB/sec
.br
The 8 * 1024 convert the value from bit/sec to kByte/sec


Video: (width * height * framerate * quality )/ (200*1024)
.br
PAL VCD Size  : (352*288*25*80) / (200*1024) = 990  kB/sec
.br
PAL FULL size : (786*576*25*80) / (200*1024) = 4260 kB/sec
.br
NTSC VCD size : (320*200*30*80) / (200*1024) = 750  kB/sec
.br
NTSC FULL size: (640*480*30*80) / (200*1024) = 3600 kB/sec

.br
The 1024 converts the Bytes to kBytes. Not every card can record the size 
mentioned. The Buz for examples can only record a size of 720x576 when
using -d 1 , the DC10 records a size of 384x288 when using -d 2.

.br
When you add audio and video datarate, this is what your hard disk has  
to be able to write constantly streaming, else you will have lost frames.

.SH "RECORDING VIDEOS"
.br 

Recording with lavrec look's like this:
.br 
.B > lavrec \-f a \-i P \-d 2 record.avi

Should start recording now,
.br 
\-f a: use AVI as output format,
.br 
\-i P: use as input source the SVHS\-In with PAL format,
.br 
\-d 2: the size of the pictures are half size (352x288)
.br 
record.avi: name of the created file.
.br 
Recording is finished by pressing Crtl\-C (nowadays: Strg\-C).

Other example:
.br 
.B > lavrec \-f q \-i n \-d 1 \-q 80 \-s \-l 80 \-R l \-U record.mov

Should start recording now,
.br 
\-f q : use Quicktime as output format,
.br 
\-i n : use Composit\-In with NTSC format,
.br 
\-d 1 : record pictures with full size (640x480)
.br 
\-q 80: set the quality to 80% of the captured image
.br 
\-s   : use stereo mode (default mono)
.br 
\-l 80: set the recording level to 80% of the max during recording
.br 
\-R l : set the recording source to Line\-In
.br
\-U   : With this lavrec usese the read instead of mmap for recording this
is needed if your sound card does not support the mmap for recording.

The cards record at a different size in PAL when recording at -d 1 :
.br
BUZ and LML33: 720x576 and the DC10: 768x576


Other example:
.br 
.B > lavrec \-w \-f a \-i S \-d 2 \-l \-1 record%02d.avi

Should start recoding:
.br 
\-w   : Waits for user confirmation to start (press enter)
.br 
\-f a : use AVI as output format,
.br 
\-i S : use SECAM SVHS\-Input (SECAM Composit recording is also possible: \-i s)
.br 
\-d 2 : the size of the pictures are half size
.br 
\-l \-1: do not touch the mixer settings.
.br 
record%02d.avi : Here lavrec creates the first file named record00.avi after 
the file has reached a size of 1.6GB (after about 20 Minutes recording) it 
starts a new sequence named record01.avi and so on, till the recording is 
stopped, or the disk ist full. 

Other example:
.br
.B > lavrec -f a -i t -q 80 -d 2 -C europe-west:SE20 test.avi
.br
Should start recording now,
.br
\-f a : use AVI as output format,
.br
\-i t : use tuner input
.br
\-q 80: set the quality to 80% of the captured image
.br
\-d 2 : the size of the pictures are half size (352x288)
.br
\-C ..:choose TV channels, and the corresponding -it and -iT 
(video source: TV tuner) can currently be used on the Marvel G200/G400 and 
the Matrox Millenium G200/G400 with Rainbow Runner extension (BTTV-Support 
is under construction).  For more information on how to make the TV tuner 
parts of these cards work, see the Marvel/Linux project on: 
http://marvel.sourceforge.net 

Last example:
.br
.B > lavrec -f a -i p -d 2 -q 80 -s -l 70 -R l --software-encoding test03.avi 
.br
The only not known option is 
.B --software-encoding, 
this enables the software encoding of the recorded images. With this option 
you can also record from a bttv based card. The processor load is high. It 
also works with zoran based cards but only with -d 4.
.br

All lavtools accept the %02d file description, so you do not have to name each 
file, but that would also be a posibillity to do. 
.br

Note: More options are described in the lavrec man-page. 
.br

There are more options, but with this you should be able to start.
.br
 
How about some hints as to sensible settings. I habitually turn quality to
80% or more for \-d 2 capture. At full resolution as low as 40% seems to be
visually "perfect".  \-d 2 is already better than VHS video (a *lot*!).
If you're aiming to create VCD's then there is little to be gained recording
at full resolution as you need to reduce to \-d 2 resolution later anyway.

.SH "CREATING VIDEOS FROM IMAGES"
.br 
You can use jpeg2yuv to create a yuv stream from seperate JPEG images.
This stream is sent to stdout, so that it can either be saved into a
file, encoded directly to a mpeg video using mpeg2enc or used for
anything else.

Saving an yuv stream can be done like this:
.br
.B > jpeg2yuv -f 25 -j image%05d.jpg > result.yuv

Creates the file result.yuv containig the yuv video data with 25 FPS.
The -f option is used to set the frame rate. Note that image%05d.jpg means
that the jpeg files are named image00000.jpg, image00001.jpg and so on.
(05 means five digits, 04 means four digits, etc.)

If you want to encode a mpeg video directly from jpeg images
without saving a seperate video file, type:
.br
.B > jpeg2yuv -f 25 -j image%05d.jpg | mpeg2enc -o mpegfile.m1v

Does the same as above, but saves a mpeg video rather than a yuv video.
See mpeg2enc section for details on how to use mpeg2enc.

You can also use yuvscaler between jpeg2yuv and mpeg2enc.
If you want to create a SVCD from your mpeg-video, type:
.br
.B > jpeg2yuv -f 25 -j image%05d.jpg | yuvscaler -O SVCD | mpeg2enc -f 4 -o video.m2v

It's also usefull to put yuvmedianfilter before mpeg2enc. The resulting
video will be softer but a bit less sharp:
.br
.B > jpeg2yuv -f 25 -j image05d*.jpg | yuvmedianfilter | mpeg2enc -o video.m1v

It also depends on the quality (compression) of your jpeg images wheather
yuvmedianfilter should be used or not.

You can use the -b option to set the number of the image to start with.
For example, if your first image is image01.jpg rather than image00.jpg, type:
.br
.B > jpeg2yuv -b 1 -j image%02d.jpg | yuv2lav -o stream_without_sound.avi

Adding the sound to the stream then:
.br
.B > lavaddwav stream_without_sound.avi sound.wav stream.avi

The number of images to be processed can be specified with the -n number.


.SH "CHECKING IF RECORDING WAS SUCCESFUL"
.br 
You can use lavplay or glav.

.B > lavplay \-p S record.avi

You should see the recorded video and hear the sound. But the decoding of the
video is done by the CPU. Your system has quite a heavy load. You don't need
xawtv or anything, though.

When you record with -d 1 somtimes it happend that the field were described 
wrong top first, but it was a bottom first video. You notice this effect easily
when you look at the logo of a tv company. Then try to play it back with 
the -x option. This changes the field order and fix the problem. But you also have to use the -x switch in lav2yuv.
.br
But also try next time recording try to change the -f option to the opposite 
used before (a/A) this should change the field order while recording.

The better way:
.br 
.B > lavplay \-p H record.avi

The video is decoded and played by the hardware. The system load is now
very low. This will play it back on\-screen using the hardware.

You might also try:
.br 
.B > lavplay \-p C record.avi

Which will play it back using the hardware, but to the output of the card, so
you'll be able to use xawtv or another tv application to see the results.

NOTE: ALWAYS first open xawtv, and only then, start lavplay \-p C. If you do it
the other way around, the computer might crash.

.B > glav record.avi

Does the same as lavplay, but you have an nice gui. The options for glav and 
lavplay are nearly the same. Using no option HW playback is used. 

Using hardware playback a signal for the Composit and SVHS OUT is generated, so you can view the movie on your TV.

NOTE: After loading the driver's you have to start xawtv to set up some things
lavplay and glav do not, but they are needed for HW\-Playback. Don't forget to
close xawtv !!
.br 
NOTE2: Do not try to send glav an lavplay into background, wont work correct !!!
.br 
NOTE3: SECAM playback is now (12.3.2001) only in monochrome, but the recording
and encoding is done right.

Coming soon: There is a tool, that makes recording videos very simple named
Linux Video Studio. You can download it at: http://ronald.bitfreak.net


.SH "EDIT THE VIDEO"
.br 
Most of tasks can be easily done by glav.
Like deleting parts of the video, cut paste and copy parts of the videos.
I for my term, I was not in the need of doing anything that glav coudn't do.

The modification's should be saved because glav does not edit (not destructive)
the video. This means that the video is left untouced, and the modification's
are kept in an extra "Edit List" file. Readable with a text editor. This files
can be used as an input file for the lavtools, like lav2wav, lav2yuv, lavtrans.

If you want to cut off the beginning and the end of the stream mark the
beginning and the and, and use the "save select" button. The edit list file is
than used as input for the lavtools. If you want to split a recorded video to
some smaler parts, simply select the parts and then save each part to a differnt
listfile.

You can see all changes to the video and sound NOW, you do not need to
recalculate something.

If you want to get an "destructive" version of your edited video use:
.br

.B > lavtrans \-o short_version.avi \-f a editlist.eli
.br
\-o    : specifies the output name
.br
\-f a  : specifies the output format (AVI for example)
.br
editlist.eli : is the list file where the modifications are descibed. You
generate the list file with the "save all" or "save select" buttons in glav.

Unify videos:
.br

.B > lavtrans \-o stream.movtar \-f m record_1.avi record_2.avi ... record_n.avi
.br
\-o  : specifies the output name
.br
\-f m: specifies the output format, movtar in this case

This is usually not necessary. Keep in your mind that there is the 2GB file-size-limit on 32Bit systems with an older glibc. 

Separate pics and sound: 

.B > lavtrans \-o sound.wav \-f w stream.avi
.br
Creates a wav file with the sound of the stream.avi
.br
Maybe need if you want to remove noise or something else, or you want to
convert it to an an other sound format for other use.

An other version of spliting the sound is:
.br
.B > lav2wav editlist.eli > sound.wav

Creating seperate images:
.br
.B > mkdir jpg
.br
.B > lavtrans \-o jpg/image%05d.jpg \-f i stream.avi
.br
First create the directory "jpg".
.br
Then lavtrans will create single JPG images in the jpg directory from the
stream.avi file. The files will be named: image00000.jpg image00001.jpg ....

Maybe interresting if you need sample images and do not want to play around
with grabing a single image.



.SH "CREATING MOVIE TRANSITIONS"
.br 
Thanks to pHilipp Zabel's lavpipe, we can now make simple transitions between
movies or combine multiple layers of movies.

pHilipp wrote this HOWTO on how to make transitions:

Let's assume simple this scenery: We have two input videos, intro.avi
and epilogue.mov and want make intro.avi transist into epilogue.mov
with a duration of one second (that is 25 frames for PAL or 30 frames
for NTSC).

intro.avi and epiloque.mov have to be of the same format regarding
frame rate and image resolution, at the moment.
In this example they are both 352x288 PAL files. intro.avi contains
250 frames and epilogue.mov is 1000 frames long.

Therefore our output file will contain:
 \- the first 225 frames of intro.avi
 \- a 25 frame transition containing the last 25 frames of intro.avi
   and the first 25 frames of epilogue.mov
 \- the last 975 frames of epilogue.mov

We could get the last 25 frames of intro.avi by calling:
.br
> lav2yuv \-o 225 \-f 25 intro.avi
.br
\-o 225, the offset, tells lav2yuv to begin with frame # 225
and \-f 25 makes it output 25 frames from there on
.br

Another possibility is:
.br
> lav2yuv \-o \-25 intro.avi
.br
Since negative offsets are counted from the end.

And the first 25 frames of epilogue.mov:
.br
>l av2yuv \-f 25 epilogue.mov
.br
\-o defaults to an offset of zero

But we need to combine the two streams with lavpipe. So the call would be:
.br
> lavpipe "lav2yuv \-o 255 \-f 25 intro.avi" "lav2yuv \-f 25 epilogue.mov"
.br
The output of this is a raw yuv stream that can be fed into
transist.flt.

transist.flt needs to be informed about the duration of the transition
and the opacity of the second stream at the beginning and at the end
of the transition:
.br
 \-o num   opacity of second input at the beginning [0\-255]
.br
 \-O num   opacity of second input at the end [0\-255]
.br
 \-d num   duration of transition in frames
.br
An opacity of 0 means that the second stream is fully transparent
(only stream one visible), at 255 stream two is fully opaque.
.br
In our case the correct call (transition from stream 1 to stream 2)
would be:
.br
> transist.flt \-o 0 \-O 255 \-d 25
.br
The \-s and \-n parameters equal to the \-o and \-f parameters of lav2yuv
and are only needed if anybody wants to render only a portion of the
transition for whatever reason. Please note that this only affects
the weighting calculations \- none of the input is really skipped, so
that if you pass the skip parameter (\-s 30, for example), you also
need to skip the first 30 frames in lav2yuv (\-o 30) in order to get
the expected result. If you didn't understand this, send an email to
the authors or simply ignore \-s and \-n.
.br
The whole procedure will be automated later, anyway.

Now we want to compress the yuv stream with yuv2lav.
.br
>yuv2lav \-f a \-q 80 \-o transition.avi
Reads the yuv stream from stdin and outputs an avi file (\-f a)
with compressed jpeg frames of quality 80.

Now we have the whole command for creating a transition:

>ypipe "lav2yuv \-o 255 \-f 25 intro.avi" "lav2yuv \-f 25 epilogue.mov" | \
transist.flt \-o 0 \-O 255 \-d 25 | yuv2lav \-f a \-q 80 \-o transition.avi

(This is one line.) The resulting video can be written as a LAV Edit List,
a plain text file containing the following lines:

LAV Edit List
.br
PAL
.br
3
.br
intro.avi
.br
transition.avi
.br
epilogue.mov
.br
0 0 224
.br
1 0 24
.br
2 25 999

This file can be fed into glav or lavplay, or you can pipe it into mpeg2enc
with lav2yuv or combine the whole stuff into one single mjpeg file with
lavtrans or lav2yuv|yuv2lav.



.SH "CONVERTING THE STREAM TO MPEG VIDEOS - QUICKSTART"
.br 
If you want a one command conversation to mpeg videos try lav2mpeg
in the scripts directory.

However, better results can be accomplished by trying out various options
and find out which one works best for you.  These are discussed below.


.SH "COMPRESSING AUDIO"
.br 
MPEG\-1 videos need MPEG1\-layer2 sound files, for MPEG\-2 videos you can use
MPEG1\-Layer2 and MPEG1\-Layer3 (MP3). But you should stick to MPEG1\-Layer2,
because most of the MPEG2 players (DVD Player for example, usually the
different Winxx Versions have great problems with this too) are not able to
play MPEG2\-Video and MPEG1\-Layer3 sound.

Example:
.br
.B > lav2wav stream.avi stream1.avi | mp2enc \-o sound.mp2

This creates a mpeg\-2 sound file out of the stream.avi with 224kBit/sec
bitrate. You can specifie more files, and also use the placeholder %nd.
Where n describes the numbers.

Example:
.br
.B > lav2wav editlist.eli | mp2enc \-b 128 \-m \-o sound.mp2

This creates a mono output with an bitrate of 128kBit/sec bitrate.
The input this time is the editlistfile (can have any name) created with glav,
so all changes you made in glav are direct processed and handed over to mp2enc.
So you do NOT have to create an edited stream with lavtrans to get it converted
properly.

Another example:
.br
.B > cat sound.wav | mp2enc \-v 2 \-V \-o sound.mp2

This creates an VCD ( bitrate=224, stero, sampling rate:44100) compatible
output from the wav file.
.br
With \-v 2 mp2enc is more verbose, while encoding you see the sec of audio already encodet.

The toolame encoder is also able to produce a layer 2 file. You can use that
one as well.

You can test the output with:
.br
.B > plaympeg sound.mp2

NOTE: plaympeg is a MPEG1 Player for Linux, you can use other players as well,
for MPEG audio testing you can also use mpg123.



.SH "COMPRESSING VIDEO"
.br 
You can create MPEG1 and MPEG2 videos.

Normaly the first video you create is not the best, for optimal quality/size
you need to play with the bitrate, search radius, noise filter ....
The options of mpeg2enc are described in the README in the mpeg2enc directory.

Example:
.br
.B > lav2yuv stream.avi | mpeg2enc \-o video.m1v

This creates an video file with the default bitrate of 1152kBit/sec. This is
the bitrate you need if you want to create VCD's.

Example:
.br
.B > lav2yuv \-d 2 stream%02d.avi | mpeg2enc \-b 1500 \-r 16 \-o video.m1v

There lav2yuv drops the 2 lsb (Less Significant Byte) of the each pixel. Then
mpeg2enc creates a video with a bitrate of 1500kBit/s uses an search radius of
16. That when trying to find similar 16*16 macroblocks of pixels in between
frames the encoder looks up to 16 pixels away from the current position of
each block.  It looks twice as far when comparing frames 1 frame apart and so
on. Reasonable values are 16 or 24. The default is 16, so adding the option
here is quite useless. Lower values (0, 8), improve the encoding speed, but
you get lower quality (more visible artifacts), higher values (24, 32) improve
the quality, at the cost of the speed. 
With the file description of stream%02d.avi
all files are processed that match this pattern beginning with 00, 01....

Example:
.br
.B > lav2yuv \-n 1 editlist.eli | mpeg2enc \-b 2000 \-r 24 \-q 6 \-o video.m1v

There lav2yuv applies a low\-pass noise filter to the images. Then mpeg2enc
creates an video with an bitrate of 2000kBit/s (or 2000000Bit/s) uses a search
radius of 24. Here is also the editlistfile used.

Explanation:
.br
when mpeg2enc is invoked without the 'q' flag it creates "constant bit\-rate"
MPEG streams.  Where (loosely speaking) the strength of compression (and hence
picture quality) is adjusted to ensure that on average each frame of video has
exactly the specified number of bits.  Such constant bit\-rate streams are
needed for broadcasting and for low\-cost hardware like DVD and VCD players
which use slow fixed\-speed player hardware.

Obviously, this is fairly inefficient as it means inactive scenes use up bits
that could better be "spent" on rapidly changing scenes.  Setting the q flag
tells mpeg2enc to generate variable bit\-rate streams.  For such streams the
bit\-rate specified is simply the maximum permissible.  The q parameter
specifies the minimum degree of compression to be applied by specifying 
how exactly picture information is recorded..  Typically, q would be set 
so that quiet scenes would use less than the specified maximum (around 6 
or 8) but fast moving scenes would still be bit\-rate limited.  For 
archival purposes setting a maximum bit\-rate high enough never to be 
reached (e.g. 10Mbps) and a q of 2 or 3 are reasonable choices.

Example:
.br
.B > lav2yuv \-a 352x240+0+21 stream.avi | mpeg2enc \-b 1152 \-r 16 \-4 1 \-2 1 \-o video.m1v
.br

Usually there is at the top and at the bottom a nearly black border, and a lot
of bandwith ist used for something you do not like. The \-a option sets
everything that is not in the described area to black, but the imagesize 
(352x288) is not changed.
.br
So you have a real black border, the encoder only uses a few bits for encoding
them, you are still compatible to VCD's for this example.
.br
The \-4 1 and \-2 1 options improve the quality about 10% , but conversion is
slower.

At the size of: 352x288 (1/2 PAL size, created when using the \-d 2 option when
recording) the needed bitrate is/should be between 1000 \- 1500kBit/s.

But anyways, the major factor is quality of the original and the degree of
filtering. Poor quality unfiltered material typically needs a higher rate 
to avoid visible artefacts.
.br
If you want to reduce bit\-rate without annoying artefacts when compressing
broadcast material you should try the noise filters. This are for lav2yuv: 
\-n [0..2] and \-d [0..3]

Example:
.br
.B > lav2yuv stream.avi | mpeg2enc \-b 1500 \-n s \-g 6 \-G 20 \-o video.m1v
.br

Here the stream.avi will be encoded with:
.br
\-b 1500    : a Bitrate of 1500kBit/sec
.br
\-n s       : the input Video norm is forced to SECAM
.br
\-g 6 \-G 20 : the encoder can dynamically size the output streams groups\-of\-
pictures to reflect scene changes. This is done by setting a maximum GOP 
(\-G flag) size larger than the minimum (\-g flag).
.br
For VCD's sensible values might be a minimum of 9 and a maximum of 15. For
SVCD 6 and 18 would be good values. If you only want to play it back on SW 
player you can use other min\-max values.

Example:
.br 
.B > lav2yuv \-n 1 \-a 352x220+0+34 stream%02d.avi | mpeg2enc \-b 1500 \-r 16 \-4 1 \-2 1 \-S 630 \-B 260 \-o video_n1_1500_r16_41_21_S630_B240.m1v

Here lav2yuv uses the low pass filter for optimizing the pictures, also a
part top and bottom border are set to black. lav2yuv processes all the stream
files. Then mpeg2enc uses some options that make the encoded stream look nicer.
But mpeg2enc also marks the stream so that mplex generates every 630MB a new 
stream. But the important thing that this works is that you specifie 
with the \-B option the non video (audio and mplex information) bitrate. 260 
should be fine for audio with 224kBit and mplex information. For further 
information take a look at the encoding scripts in the scripts directory.


Scaling:
.br
Using yuvscaler, one can now also scale the video before encoding it. This can be useful for users with a DC10 or DC10+ card, which captures at -d 1 768x576 or -d 2 384x288 (PAL/SECAM) or -d 1 640x480 (NTSC). 
These sizes cannot be scaled right with the -s option from lav2yuv to VCD oder SVCD format. It is only scaled right with lav2yuv when using a Buz or LML33 card. 

.br

You get a full description of all commands starting:
.br
.B >yuvscaler \-h

Using yuvscaler, one can now also downscale the video before encoding it. This 
can be useful for, for example, users with a DC10+ card, which captures at 
384x288 (PAL/SECAM) or 640x480 (NTSC) when using full resolution with
decimation two during recording.

.B >lav2yuv stream.avi | yuvscaler \-O VCD | mpeg2enc \-o video.m1v

This will rescale the 384x288 or 768x576 (PAL/SECAM) or 320x240 or 640x480
(NTSC) stream to the VCD\-size 352x288 (PAL/SECAM) or 352x240 (NTSC) and
encode the resulting output YUV data to an mpeg stream.

It can also do SVCD\-scaling to 480x480 (NTSC) or 480x576 (PAL/SECAM):
.br
.B >lav2yuv stream.avi | yuvscaler \-O SVCD \- M BICUBIC | mpeg2enc \-o video.m2v
.br 

The mode keyword (-M) forces yuvscaler to use the higher quality bicubic
algorithmus for downscaling and not the default resample algorithmus.
Upscaling is always done by the bicubic algorithmus.

Other Example
.br
.B > lav2yuv stream.avi | yuvscaler -I USE_450x340+20+30 -O SIZE_320x200 | mpeg2enc -o video.m1v

Here we only use a part of the input, and have a special output format. 

Note: yuvscaler can also set a active area, and set everything else to real
black using: -I ACTIVE_WidthxHeight+WidthOffset+HeightOffset
.br
Like the -a option in lav2yuv.

Testing is done by:
.br
.B > plaympeg video.m1v

.B Note: 
This are only examples there are more options you can use, you can use
most of them together, to create high quality videos, with the lowest 
possible bitrate.
.br 
.B Note2: 
The higher you set the search radius, the longer the conversion will 
take. In common you can say the more options used the longer it takes. 
.br
.B Note3: 
MPEG1 was not designed to be a VBR (variable bitrate stream) !!
So if you encode with -q 15 mpeg2enc sets the maximal bitrate -b to 1152.
If you want a VBR MPEG1 you have to set -b very high (2500).
.br
.B Note4: 
Maybe you should give better names than video.m1v . 
.br
A good idea would be if you see the filename you know the options you've used. 
(Ex: video_b1500_r16_41_21.m1v) 
.br
An other possibility is to call all the layer 2 files ".mp2" all the MPEG\-1 
video files ".m1v" and all MPEG\-2 video files ".m2v".  Easy to see what's 
happening then.
.br
And reserve .mpg for multiplexed MPEG\-1/2 streams.

.SH "OPTIMIZING THE STREAM"
.br
Using filters helps to increase the image quality using fixes bitrate.
Or reduces the filesize when using varibale bitrate (VBR).


Example:
.br
.B > lav2yuv stream.avi | yuvmedianfilter | mpeg2enc \-o video.m1v

Here the yuvmedianfilter programm is used to improve the image. This
removes some of low frequence noice in the images. It also sharpens 
the image a little. It takes a center pointer avg the pixels around it that 
fall with the threshold. It then replaces the center pixel with this new 
value. You can also use the \-r (radius) option for an other search radius 
, and \-t is used to control the threshold of what pixel count in the agv.
But the defaults \-r 2 and \-t 2 look good.
.br

Example:
.br
.B > lav2yuv stream.avi | yuvdenoise | mpeg2enc -o video.m1v
.br
Now we are using yuvdenoise to improve the image. The filter mainly reduces
color- and luminance-noise and flickering due to phase errors.
.br

Example:
.br
.B > lav2yuv stream.avi | yuvkineco -F 1 -S | mpeg2enc -o video.m1v
.br
yuvkineco is used for NTSC sources. It does the conversation from 29.97 fps 
to 23.976fps, you can call it "reverse 2-3 pulldown", more info about this in 
the README.2-3pulldown.  yuvkineco does only remove NTSC specific problems. 
So if you want to improve the image you should also use yuvdenoise:
.br
.B > lav2yuv stream.avi | yuvkineco | yuvdenoise | mpeg2enc -o video.m1v
.br

Example: 
.br
.B > lav2yuv stream.avi | yuvycsnoise | mpeg2enc -o video.m1v
.br
yuvycsnoise is also used for NTSC and is specialized for NTSC Y/C separation
noise. If video capture hardware has only a poor Y/C separator,at vertical
stripe (especialy red/blue), noises appear which seem checker flag and 
bright/dark invert per 1 frame. yuvycsnoise reduces noises of this type.
You can also use different thresholds for luma/chroma, and the optimizing
method. 
.br
yuvycsnoise workes only correct when we have NTSC with:
.br
* full height (480 lines)
.br
* full motion captured (29.97 fps)
.br
* captured with poor Y/C separator hardware

For more information about the yuvkineco and yuvycsnoise read the README
in the yuvfilters directory.


.SH "PUTTING THE STREAMS TOGETHER (MULTIPLEXING)"
.br
 
Example:
.br
.B > mplex sound.mp2 video.m1v \-o my_video.mpg

Puts the sound.mp2 and the video.m1v stream together to my_video.mpg

Example:
.br
.B > mplex \-S 1500 sound.mp2 video.m1v \-o my_film.mpg

Puts the sound.mp2 and video.m1v together, but the file size can be up to 1,5GB
before an second file is created. (default is 680MB)

Note that this does *not* generate seperate stand\-alone MPEG streams in each file.
This would involve ensuring each sequence started with sequence headers and
recalculating buffers and timestamps.
What currently happens is that 2nd 3rd etc files are simply *continuations* of
the 1st.  To play them you need to concatenate them and treat them as a single
looong stream. This is exactly the same (nasty) approach used on DVD's with
their 1G\-byte "VOB" files.

Now you can use your prefered MPEG player, and watch it.
All players based on the SMPG library work well.
Other Players are: xtheater, xmovie, xine, gtv for example.

Note: If you have specfied the \-S option for mpeg2enc mplex will 
automatically split the files if there is in the output filename a %d (looks 
like: \-o test%d.mpg) 
The files generated this way are sepereate stand\-alone MPEG streams!

Note: xine might have a problem with seeking through videos.

Variable bit\-rate multiplexing:
Remember to tell mplex you're encoding VBR (\-V option) as well as mpeg2enc
(see the example scripts).  It *could* auto\-detect but it is not working yet.
You should tell mplex a video buffer size at least as large as the one you
specified to "mpeg2enc".  Sensible numbers for MPEG\-1 might be a ceiling bit\-
rate of 2800Kbps, a quality ceiling (quantisation floor) of 6 and a buffer size
of 400K.

Example:
.br
.B > mplex -V -r 1740 audio.mp2 video_vbr.m1v -o vbr_stream.mpg

Here we multiplex a variabel bitrate stream. mplex is now a single pass
multiplexer so it can't dedect the maximal bitrate and we have to specify it.
The data rate for the output stream is, audio bitrate plus peak videobitrate
than add 1-2% for mplex information. If audio (-b 224) has 224kBit, video was
encodet with -b 1500 -q 9 has 1500kBit, we have 1724 * 1.01 is about 1740kBit.

Example:
.br
.B > plaympeg my_video.mpg
.br
or
.br
.B > gtv my_video.mpg


.SH "TRANSCODING OF EXISTING MPEG\-2 STREAMS"
.br 
For transcoding existing MPEG\-2 streams from digital TV cards or DVD a still
lower data\-rate than for broadcast will give good results. Standard VCD 1152
Kbps typically works just fine for MPEG1. The difference is in the Signal/Noise
ratio of the original.  The noise in the analog stuff makes it much harder to
compress.

You will also need to manually adjust the audio delay offset relative to video
when multiplexing.  Very often around 150ms delay seems to do the trick.

You have to download the ac3dec and mpeg2dec packages. You can find them at
mjpeg hompage (http://sourceforge.net/projects/mjpeg). You also need sox and
toolame if you want to use the script. 

In the scripts directory there is a trancode script that does most of the work.

So transcoding looks like this:
.br  
\fB> transcode \-V \-o vcd_stream mpeg2src.mpg\fR
.TP 6
.B \\-V : 
set's the options so that a VCD compatible stream is generated
.TP 15
.B \\-o vcd_stream: 
a vcd_stream.m1v (video) and vcd_stream.mp2 (audio) is created
.TP 15
.B \mpeg2src.mpg: 
specifies the source stream
.TP 0

The script prints also something like this:
.br 
> SYNC 234 mSec

You will need to adjust the audio/video startup delays when multiplexing to
ensure audio and video are synchronised.
.br 
The exact delay (in milliseconds) that you need to pass to mplex to synchronise
audio and video using the "\-O" is printed by the extract_ac3 tool labelled
"SYNC" when run with the "\-s" flag.

Then you need to multiplex them like this:
.br 
\fB> mplex \-f 1 \-O 234 vcd_stream.mp2 vcd_stream.m1v \-o lowrate.mpg\fR
.TP 9
.B \\-f 1   : 
Mux format is VCD
.TP 9
.B \\-O 234 : 
Video timestamp offset in mSec, generated by the lavtrans script, there negative values are allowed
.TP 0
.br 
vcd_stream.mp2i & vcd_stream.m1v : generated files
.br 
lowrate.mpg  : the VCD compatible output stream


> transcode \-S \-o svcd_stream mpeg2src.mpg
.br 
Here the output format is SVCD (MPEG\-2 video).

You have to multiplex it with:
.br 
\fB> mplex \-f 4 \-O 234 svcd_stream.mp2 svcd_stream.m2v \-o lowrate.mpg\fR

There is sometimes a problem with NTSC and VCD playback because movies may be
recorded with 3:2 pulldown NTSC with 60 fields/sec. mpeg2dec is designed for
playback on computers, and generates the original 24frames/sec bitrate. If you
encode the video now, an 30frames/sec video is created. This video is now much
to short for the encoded audio.
.br 
This encoding works now but you have to do it manual:

\fB> cat mpeg2src.mpg | mpeg2dec \-s YUVs | buffer \-b 4M |
 mpeg2enc \-I 0 \-f 4 \-q 9 \-V 200 \-b 2500 \-F 1 \-p \-o svcd_stream.m2v\fR

The \-F 1 options tells mpeg2enc the frame rate for the encoded video has to
be 24000.0/1001.0 (NTSC 3:2 pulldown converted FILM). The \-p tells mpeg2enc
to generate header flags for 32 pull down of 24fps movie. It may also work if
you do not add the \-p flag.

You do not need the \-p flag because it is not supported in mpeg1.

If you want to do every step on your own it has to look like this:

Extracting Audio:
.br 
\fB> cat test2.mpg | extract_ac3 \- \-s | ac3dec \-o wav \-p sound.wav 2>/dev/null\fR

One of the first lines showed contains the label "SYNC" you have to use this
time afterwards for the multiplexing. The 2>/dev/null redirects the output of
ac3dec to /dev/null. In the next step you generate the mpeg audio file:

\fB> cat sound.wav | mp2enc \-V \-v 2 \-o audio.mp2\fR
.TP 6
.B \\-V  : 
forces VCD format, the sampling rate is converted to 44.1kHz  from 48kHz
.TP 6
.B \\-v 2: 
unnecessary but if you use it mp2enc tells you how many seconds of the 
Audio file are already encoded.
.TP 6
.b \\-o  : 
Specifies the output file.
.TP 0

You can generate VCD and SVCD videos, and own mpeg1/2 videos.

For VCD creation use:

\fB> cat test2.mpg | mpeg2dec \-s \-o YUVh | buffer \-b 4M | 
 mpeg2enc \-f 1 \-o video_vcd.m1v\fR

mpeg2dec:
.TP 6
.B \\-f 1 : 
tells mpeg2dec to use program stream demultiplexer
.TP 11
.B \\-o YUVh :
the output size of the extracted frames
.TP 0

There are other output modes, try "mpeg2dec \-\-help" but the most important here are:
.TP 7
.B YUV  : 
is the full image size
.TP 7
.B YUVs : 
is SVCD size
.TP 7
.B YUVh : 
is VCD size
.TP 0

Mplex with:
.br 
\fB> mplex \-f 1 audio.mp2 video_vcd.m1v \-o vcd_stream.mpg\fR

.TP 7
.B \\-f 1 : 
generates an VCD stream
.TP 0 

For SVCD creation use:
.br 
\fB> cat test2.mpg | mpeg2dec \-s \-o YUVs | buffer \-b 4M |
 mpeg2enc \-f 4 \-I 0 \-q 9 \-V 200 \-b 2500 \-s \-o video_svcd.mpg\fR

.TP 9
.B \\-f 4   : 
Set options for MPEG 2 SVCD
.TP 9
.B \\-I 0   :
No field pictures, the pictures are not interlaced.
.TP 9
.B \\-q 9   :
Quality factor for the stream (VBR stream)
.TP 9
.B \\-V 200 :
Target video buffer size in KB
.TP 9
.B \\-b 2500:
Maximal video bitrate for the VBR stream
.TP 9
.B \\-o     :
Output file
.TP 0 

Mplex with:
\fB> mplex \-f 4 \-V \-r 2755 audio.mp2 video_svcd \-o svcd_stream.mpg\fR

.TP 10
.B \\-f 4 : 
generate an SVCD stream
.TP 10
.B \\-V : 
Multiplex variable bit-rate video
.TP 10
.B \\-r 2755: 
Specify data rate of output stream in kbit/sec
.TP 0

For other video output formats this might work:
\fB> cat test2.mpg | mpeg2dec \-s \-o YUV | buffer \-b 4M | 
 yuvscaler yuvscaler \-O SIZE_320x200 \-O NOT_INTERLACED |
 mpeg2enc \-o strange_video.m1v\fR

If you want to reedit mpeg streams, this also works, but in a slightly different
way. For demultiplexing you can use bbdmux, from the bbtools package.  Splits
out either video or audio very cleanly. Look for the linux port at the bottom.
.br
Available at: http://members.home.net/beyeler/bbmpeg.html

First run:
.br
.B > bbdmux myvideo.mpg

You should get something like this:
.br
Found stream id 0xE0  = Video Stream 0
.br
Found stream id 0xC0  = MPEG Audio Stream 0
.br
Found stream id 0xBE  = Padding Stream

Extract audio with:
.br
.B > bbdmux myvideo.mpg 0xC0 audio.mp1

Convert it to wav:
.br
.B > mpg123 -w audio.wav audio.m1v

Extract video with:
.br
.B > bbdmux myvideo.mpg 0xE0 video.m1v
.br

Converting video to an mjpeg avi stream:
.br
.B > cat video.m1v | mpeg2dec -o YUV | yuv2lav -f a -o test.avi
.br

Then adding the sound to the avi:
.br
.B > lavaddwav test.avi audio.wav final.avi

If the source video has already the size of the target video use -o YUV, using
YUVh, makes the video the half size !!

The rest can be done just like editing and encoding other streams.

If you have videos with ac3 sound you only have to adapt the commands above.

Extracting Audio:
.br
.B > cat test2.mpg | extract_ac3 - -s | ac3dec -o wav -p sound.wav 2>/dev/null

Extract video:
.br
.B > cat test2.mpg | mpeg2dec -s -o YUVh | buffer -b 4M | yuv2lav -f a -q 85 -o test.avi

Adding the sound:
.br
.B > lavaddwav test.avi sound.wav fullvideo.avi

NOTE: You need much space. 1GB of video has afterward a size of about 2GB at SVCD
size. Plus some temp files. Converting the Video the mjpeg also takes some time.

On my Athlon 500 I never get more than 6-7 Frames a second.
.br
You loose quality each time you convert a stream into an other format !

.SH "TRADING QUALITY/SPEED"
.br 
If absolute quality is your objective a modest improvement can be archieved
using the \-4 and \-2 flags. These control how ruthlessly mpeg2enc discards
bad\-looking matches between sections of adjacent frames during the early
stages of the search when it is working with 4*4 and 2*2 clusters of pixels
rather than individual pixels. Setting \-4 1 \-2 1 maximises quality.  \-4 4
\-2 4 maximises speed.  Note that because the statistical criteria mpeg2enc
uses for discarding are usually fairly reliable the increase/decrease in
quality is fairly marginal.

Reducing the radius of the search for matching sections of images also
increases speed.  However, due to the way the search algorithm works the
search radius is in effect rounded to the nearest multiple of 8. Furthermore,
on modern CPU's the speed gained by reducing the radius below 16 is not so
huge that the very marked quality reduction is likely to be worthwhile for
most applications.

Creating streams to be played from disk using Software players

Usually MPEG player software is much more flexible than the hardware built into
DVD and VCD players.  This flexibility allows for significantly better
compression to be achieved for the same quality.
The trick is to generate video streams that use big video buffers (500KB or
more) and variable bit\-rate encoding (the \-q flag to mpeg2enc and \-V for
mplex).  Software players will often also correctly play back the much more
efficient MPEG layer 3 (yes, "MP3") audio format. A good Mp3 encoder like
lame will produce results comparable to layer 2 at 224Kbps at 128Kbps or
160Kbps.



.SH "CREATING VIDEO\-CD'S"
.br 
There are some limitations on VCD's
.br
Like bitrate for video 1152kBit and for audio 224kBit.
.br
For audio use:
.br
.B > lav2wav stream.avi | mp2enc \-V \-o sound.mp2

\-V force VCD compatible output (same as: \-b 224 \-r 44100 \-s)
For hardware players, you should stick to 44.1 224kBps Stereo layer 2 Audio.

For the video use:
.br
.B > lav2yuv stream.avi | yuvscaler \-O VCD | mpeg2enc \-f 1 \-r 16 \-o video.m1v

For a VCD compatible output the -f 1 sets all options in mpeg2enc as 
needed. Never try for VCD \-m or \-b. It seems that many VCD players (Avex
for example) are not able to play MPEG streams that are encoded with a search
radius greater than 16. But \-r 16 workes fine.

Mplex with:
.br
.B > mplex \-f 1 sound.mp2 video.m1v \-o vcd_out.mpg

The \-f 1 option turns on a lot of weird stuff that otherwise has no place
in a respectable multiplexer!

Creating the CD:
The multiplexed streams have to be converted to an VCD compatible.
This ist done by vcdimager

Example:
.br
.B > vcdimager testvideo.mpg

Creates a videocd.bin, the data file, and a videocd.cue which is used as
controllfile for cdrdao.

In Linux you can use cdrdao to burn the image.
.br
Aviable at: http://cdrdao.sourceforge.net/index.html

For MPEG\-1 encoding a typical (45 minute running time) show or 90 odd
minute movie from an analog broadcast a constant bit\-rate of around 1800
kBit/sec should be ideal.  The resulting files are around 700M for 45 minutes 
which fits nicely as a raw XA MODE2 data track on a CD\-R.

For pure digital sources (DTV or DVD streams and similar) VCD 1152 works
fine.
.br

.B Note:
If you encode VBR MPEG1 (-q) remember the Hardware was not bulit do
the playback because it is not in the specifications. If it works be very
happy. I've notices that it helps when you have an MPEG1 Stream to tell
vcdimager that it ist an svcd. vcdimager complains, but you should be able
to burn it. This could convince the player to use an other firmware and play
it back correct, but there is no guarantee for that.

Storing MPEG's.
If you record the data as XA mode 2 tracks you can fit appreciably more
on a CD (at the expense of error correction/detection).  You can use
vcdimager to do this and readvcd to extract the resulting files.

For better Quality there are SVCD and XVCD and DVD.
Currently only SVCD is fully supported with a pre\-set format in mplex
and tools to create disks. MPEG streams that can be played by DVD player
hardware and software can readily produced using mpeg2enc/mplex but there
is currently no means to make a properly structured disk image. 

If your player doesn't support SVCD however, you may well find it can
handle VCD streams that have much higher than standard bit\-rates.Often
as much as 2500kBit/sec is possible.  With higher bit\-rates and good
quality source material it is worth trying mpeg2enc's \-h flag which
produce a stream that is as sharp as the limits of the VCD standard
permits. The \-h flag seems to help also if there is a low quality stream, 
the video does not look that sharp using the flag, but there are not that 
much gitches as without it. 

However, if your player supports it and you have the patience for the
much longer encoding times SVCD is a much better alternative.  Using
a more efficient MPEG format SVCD more than doubles VCD's resolution
while typically producing files that are rather less than twice as
big.



.SH "CREATING SVCD'S"
.br 
Record at full TV resolution (means: \-d 1  for PAL this is 720x568)
.br

Convert the sound with:
.br
.B > lav2wav stream.avi | mp2enc \-v \-o sound.mp2

Convert the video with:
.br
.B > lav2yuv stream.avi | yuvscaler \-O SVCD | mpeg2enc \-f 4 \-I 3 \-b 2500 \-q 7 \-V 200 \-o video.m2v

.br
.B \\-f 4
sets the options for mpeg2enc to SVCD
.br
.B \\-b 2500 & -q 7 
tell mpeg2enc to generat a variable bitrate stream but with a maximal Btrate of 2500kBit/sec
.B \\-I 3 
tell mpeg2enc to assume that the original signal is field interlaced
video where the odd rows of pixels are sampled a half frame interval after
the even ones in each frame. The \-I 0 (progressive output (no field
pictures)) option will also work for PAL.
.br
.B \\-I 1 
and 
.B \\-I 2
will work but are currently handicapped by rather dumb code to choose the type of motion compensation.

You can use lower bitrates, but the SVCD standard limits total bit\-rate
(audio and video) to 2788800 Bit/sec. So with 224Kbps audio and overheads
2550 may already be marginally too tight.

SVCD supports variable bitrate (VBR), because MPEG2 is usually VBR, but with
the top video bitrate limit of 2500kBit/sec. True VBR Streams -q X only are 
likely to fail on SVCD/DVD Players. With the -f 4 flag the encoder also sets 
dynamic GOP with a low limit of -g 6 and a high limit of -G 18.

An other possibility for movies in PAL (European style 25 frames/50 fields
per sec) video is:

.B > lav2yuv stream.avi | yuvscaler \-O SVCD | mpeg2enc \-f 4 \-I 0 \-b 2500 \-V 400 \-o video.m2v

Movies are shot on film at 24 frames/sec.  For PAL broadcast the film is
simply shown slightly "too fast" at 25 frame/sec (much to the pain of people
with an absolute pitch sense of pitch).  The \-I 0 flag turns off the tedious
calculations needed to compensate for field interlacing giving much faster
encoding.

Unfortunately, movies broadcast in NTSC (US style 30 frames/60 fields sec)
video this will produce very poor compression.  The "pulldown" sampling
used to produce 60 fields a second from a 24 frame a second movie means
half the frames in an NTSC *are* field interlaced.

For SVCD\-encoding, you can of course also use yuvscaler for the downscaling
rather than letting mpeg2enc do that.
.br 

Multiplex with:
 
.B > mplex \-f 4 \-V \-b 400 \-r 2750 sound.mp2 video.m2v \-o vcd_out.mpg

.TP 8
.B \\-f 4 
tells mplex to encode a SVCD,
.TP 8
.B \\-V 
with a variable Bitrate
.TP 8
.B \\-r 2750 
is the calculated Audio + Video Bitrate + 1-2% multiplex information
.TP 8
.B \\-b 400
is the Buffer aviable on the plaback device, the same used for the video encoding (there the -V option).
.TP 0

Creating the CD:

Example:
.br
.B > vcdimager \-t svcd testvideo.mpg

Creates an videocd.bin, the data file, an a videocd.cue which is used as
controllfile for cdrdao.

In Linux use cdrdao to burn the image.

Note: If you want to build "custom" VCD/SVCD you should try the 
mplex -f 2 and -f 5 switches.

Note: The VCD SVCD stuff may work on your HW player or not. There are
many reports that it works quite well. Don't be woried if it does not
work. Nor am I responsible for unusable CDs.

vcdimager is aviable at: 
.br
http://www.hvrlab.org/~hvr/vcdimager/


.SH "INTEROPERABILITY"
.br 
Quicktime files capturing using lavrec can be editted using Broadcast2000.
mjpeg AVI files captured using the streamer tool from the xawtv package
can be editted and compressed and played back using software.  Hardware
playback is not possible for such files due to limitations in the Zoran
hardware currently supported.

MPEG files produced using the tools are know to play back correctly on:
.br
dxr2 (hardware decoder card)
.br
mtv				MPEG1 only
.br
xine
.br
oms
.br
dvdview
.br
xmovie
.br
gtv				MPEG1 only
.br
mplayer
.br
vlc
.br
ztheater
.br
MS Media player version 6 and 7
.br
SW DVD Player

.SH "FILES"
.br 
.LP 
\fI/usr/local/bin\fP 
.br 
There you find the files after the install of the package,
or a make install for a tar or a cvs download
.SH "ENVIRONMENT VARIABLES"
.LP 
.TP 
\fBLAV_VIDEO_DEV\fP
Specifies the video device used by the mjpeg tools
.TP 
\fBLAV_AUDIO_DEV\fP
Specifies the audio device used by the mjpeg tools
.TP 
\fBLAV_MIXER_DEV\fP
Specifies the mixer device used by the mjpeg tools

.SH "AUTHORS"
.br 
.LP 
If you have any problems or suggestions feel free to mail me (Bernhard
Praschinger): waldviertler@users.sourceforge.net

There is a lot of stuff added from the HINTS which Andrew Stevens
(wackston@users.sourceforge.net) created.

And there a some people that helped me with programm descriptions
and hints, 
.br
thanks
.br

If you have questions, remarks, problems or you just want to contact
the developers, the main mailing list for the MJPEG\-tools is:
  mjpeg\-users@lists.sourceforge.net

Although little bits have been done by everyone the main work was
roughly as follows:

lav* : Ronald Bultje <rbultje@ronald.bitfreak.net>, Gernot Ziegler <gz@lysator.liu.se> 
.br 
mpeg2enc mplex bits\-and\-pieces : andrew.stevens@planet\-interkom.de
.br 
libmjpeg, libmovtar: Gernot Ziegler <gz@lysator.liu.se>

Many thanks and Kudos to Rainer Johanni the original author who
started this all and did most of the hard work in the lavtools.

.SH "SEE ALSO"
.br 
.LP 
The mjpeg hompage ist at:
.br 
http://mjpeg.sourceforge.net/
.br 
http://sourceforge.net/projects/mjpeg

vcdimager  is aviable at: 
.br 
http://www.hvrlab.org/~hvr/vcdimager/
.br 

cdrdao   is aviable at:
.br 
http://cdrdao.sourceforge.net/index.html
.br 

Linux Video Studio is aviable at:
.br 
http://ronald.bitfreak.net

The lavtools:
.br 
.BR lav2wav(1),
.BR lav2yuv(1),
.BR lavpipe(1),
.BR lavplay(1),
.BR lavrec(1),
.BR lavtrans(1),
.BR mp2enc(1),
.BR mpeg2enc(1),
.BR mplex(1),
.BR yuv2lav(1),
.BR yuvplay(1),
.BR yuvscaler(1),

.br
Tools without a man page: jpeg2yuv, yuvdenoise, lavaddwaw, glav, yuvmedianfilter, yuvdenoise, yuvkineco, yuvycsnoise
